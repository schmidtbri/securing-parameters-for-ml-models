{
 "cells": [
  {
   "cell_type": "raw",
   "id": "561a9ee2",
   "metadata": {},
   "source": [
    "Title: Signed Parameters for Secure ML Model Deployments\n",
    "Date: 2023-03-17 22:00\n",
    "Category: Blog\n",
    "Slug: securing-parameters-for-ml-models\n",
    "Authors: Brian Schmidt\n",
    "Summary: In the Python ecosystem, using pickle to serialize machine learning models is very common. Pickle is a built-in Python library module that makes it easy to convert in-memory objects into bytestreams that can be saved to a hard drive or sent over networks. Pickling an object is very quick and simple and is the easiest way to persist a complex Python object for later use. However, pickle is not a secure serialization standard. The documentation for the pickle module in the Python standard library explicitly mentions the insecure nature of the pickle format: Warning The pickle module is not secure. Only unpickle data you trust. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never unpickle data that could have come from an untrusted source, or that could have been tampered with. In this blog post, we'll be downloading a dataset, exploring it, training a model, signing the model parameters, and deploying the model parameters and model to a Kubernetes cluster as a RESTful service. We'll also be loading the model parameters from a network storage service to show how to secure the model parameters while they are stored separately from the model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a5fe3",
   "metadata": {},
   "source": [
    "# Signed Parameters for Secure ML Model Deployments\n",
    "\n",
    "This blog post was written in a Jupyter notebook, the code and commands found in it reflect this.\n",
    "\n",
    "All of the code for this blog post is in [this github repository](https://github.com/schmidtbri/securing-parameters-for-ml-models).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the Python ecosystem, using pickle to serialize machine learning models is very common. Pickle is a built-in Python library module that makes it easy to convert in-memory objects into bytestreams that can be saved to a hard drive or sent over networks. Pickling an object is very quick and simple and is the easiest way to persist a complex Python object for later use. However, pickle is not a secure serialization standard. The [documentation](https://docs.python.org/3/library/pickle.html) for the pickle module in the Python standard library explicitly mentions the insecure nature of the pickle format:\n",
    "\n",
    "```quote\n",
    "Warning The pickle module is not secure. Only unpickle data you trust.\n",
    "\n",
    "It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never unpickle data that could have come from an untrusted source, or that could have been tampered with.\n",
    "```\n",
    "\n",
    "What can we do about this? Pickling is the easiest way to save model objectsand using pickle for model serialization is ubiquitous in Data Science. One thing that we can do is make sure that the pickle files that hold our models are not modified in the time between the training process and the prediction process. This way, we can be sure that the contents of the file are benign. This is especially important in models that are deployed in production services that are running in sensitive environments. If we allow the model service that is hosting the model to load a pickle file that has been compromised, we can allow arbritrary code execution on the server. \n",
    "\n",
    "One way to prevent the pickle file from being modified is by \"signing\" it. Signing a file means processing the data and creating a \"signature\" that we can use later to make sure that the contents of the file have not been changed since it was signed. In order to still be able to use pickle in a production setting, we'll require that the model parameters be signed right after they are created, then we'll check the signature before we load the parameters within the model service. If the signature does not match, we'll know that the model parameters are not safe to load. However, signing model parameters does not encrypt them, so it is still possible for someone with access to the pickle files to view the model parameters.\n",
    "\n",
    "In this blog post, we'll be downloading a dataset, exploring it, training a model, signing the model parameters, and deploying the model parameters and model to a Kubernetes cluster as a RESTful service. We'll also be loading the model parameters from a network storage service to show how to secure the model parameters while they are stored separately from the model deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3ca1a",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "In order to train a model, we'll need a dataset. The dataset we've chosen is the [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset) available from Kaggle. The dataset contains data about health and the incidence of diabetetes. We'll be using the dataset to train a model that predicts whether or not a person is likely to have diabetes.\n",
    "\n",
    "To make it easy to download the data, we'll install the [kaggle python package](https://pypi.org/project/kaggle/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f8b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "%pip install kaggle\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e01a6",
   "metadata": {},
   "source": [
    "Next, we'll execute these commands to download the data and unzip it into the data folder in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f7c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data\n",
    "\n",
    "!kaggle datasets download -d alexteboul/diabetes-health-indicators-dataset -p ../data --unzip\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd15dc7",
   "metadata": {},
   "source": [
    "The files downloaded look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa5e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 101232\r\n",
      "drwxr-xr-x   5 brian  staff       160 Mar 17 22:55 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  25 brian  staff       800 Mar 17 22:55 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 brian  staff  22738151 Mar 17 22:55 diabetes_012_health_indicators_BRFSS2015.csv\r\n",
      "-rw-r--r--   1 brian  staff   6347570 Mar 17 22:55 diabetes_binary_5050split_health_indicators_BRFSS2015.csv\r\n",
      "-rw-r--r--   1 brian  staff  22738154 Mar 17 22:55 diabetes_binary_health_indicators_BRFSS2015.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73014462",
   "metadata": {},
   "source": [
    "We'll focus on the \"diabetes_binary_5050split_health_indicators_BRFSS2015.csv\" dataset. Let's load the dataset into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2306b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(f'../data/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ca2770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70692, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3b104",
   "metadata": {},
   "source": [
    "The unprocessed dataset has 70692 rows and 22 columns.\n",
    "\n",
    "The dataframe columns are these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d47c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70692 entries, 0 to 70691\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Diabetes_binary       70692 non-null  float64\n",
      " 1   HighBP                70692 non-null  float64\n",
      " 2   HighChol              70692 non-null  float64\n",
      " 3   CholCheck             70692 non-null  float64\n",
      " 4   BMI                   70692 non-null  float64\n",
      " 5   Smoker                70692 non-null  float64\n",
      " 6   Stroke                70692 non-null  float64\n",
      " 7   HeartDiseaseorAttack  70692 non-null  float64\n",
      " 8   PhysActivity          70692 non-null  float64\n",
      " 9   Fruits                70692 non-null  float64\n",
      " 10  Veggies               70692 non-null  float64\n",
      " 11  HvyAlcoholConsump     70692 non-null  float64\n",
      " 12  AnyHealthcare         70692 non-null  float64\n",
      " 13  NoDocbcCost           70692 non-null  float64\n",
      " 14  GenHlth               70692 non-null  float64\n",
      " 15  MentHlth              70692 non-null  float64\n",
      " 16  PhysHlth              70692 non-null  float64\n",
      " 17  DiffWalk              70692 non-null  float64\n",
      " 18  Sex                   70692 non-null  float64\n",
      " 19  Age                   70692 non-null  float64\n",
      " 20  Education             70692 non-null  float64\n",
      " 21  Income                70692 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749cf3d7",
   "metadata": {},
   "source": [
    "The columns names are not all easy to understand so we'll rename some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a12fc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns = {\n",
    "    \"Diabetes_binary\": \"Diabetes\",\n",
    "    \"HighBP\": \"HighBloodPressure\",\n",
    "    \"HighChol\": \"HighCholesterol\",\n",
    "    \"CholCheck\": \"CholesterolChecked\",\n",
    "    \"HeartDiseaseorAttack\": \"HeartDiseaseOrHeartAttack\",\n",
    "    \"PhysActivity\": \"PhysicalActivity\",\n",
    "    \"HvyAlcoholConsump\": \"HeavyAlchoholConsumption\",\n",
    "    \"NoDocbcCost\": \"NoDoctorsVisitBecauseOfCost\",\n",
    "    \"GenHlth\": \"GeneralHealth\",\n",
    "    \"MentHlth\": \"MentalHealth\",\n",
    "    \"PhysHlth\": \"PhysicalHealth\",\n",
    "    \"DiffWalk\": \"DifficultyWalking\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf01056",
   "metadata": {},
   "source": [
    "## Profiling the Data\n",
    "\n",
    "In order to profile the data, we'll use the [sweetviz](https://github.com/fbdesignpro/sweetviz) package. Let's install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40bdbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sweetviz\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a68ce2",
   "metadata": {},
   "source": [
    "To profile the data, all that is needed is two lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8447cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "report = sv.analyze(data)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39bf610",
   "metadata": {},
   "source": [
    "Once the report is created, we'll save it to disk as an HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fc236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report ../diabetes_risk_model/model_files/data_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "report.show_html(filepath=\"../diabetes_risk_model/model_files/data_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf16f728",
   "metadata": {},
   "source": [
    "Right away the profile will tell us a few key details about the dataset:\n",
    "\n",
    "![Data Overview](data_overview_spfmlm.png)\n",
    "![Data Overview]({attach}data_overview_spfmlm.png){ width=100% }\n",
    "\n",
    "The dataset has 1635 duplicate rows, it has 22 features, 18 of which are categorical and 4 of which are numerical. The profile has a description for each variable. Here's the description for the \"Diabetes\" variable, which we'll use as the target variable.\n",
    "\n",
    "![Variable Overview](variable_overview_sdfmlm.png)\n",
    "![Variable Overview]({attach}variable_overview_sdfmlm.png){ width=100% }\n",
    "\n",
    "By using the sweetviz package we can avoid writing the most common data profiling code. From the report we can tell that there are a few things we'll need to deal with:\n",
    "\n",
    "- There are highly correlated variables.\n",
    "- Some variables have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988abb65",
   "metadata": {},
   "source": [
    "## Training a Model\n",
    "\n",
    "To train a model we'll be using the [pycaret package](https://pycaret.org/).\n",
    "\n",
    "Let's install the package first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f978bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --pre pycaret\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f05e4",
   "metadata": {},
   "source": [
    "We'll setup the experiment like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be8df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8dfdd_row8_col1, #T_8dfdd_row12_col1, #T_8dfdd_row14_col1, #T_8dfdd_row16_col1, #T_8dfdd_row18_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8dfdd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8dfdd_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_8dfdd_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8dfdd_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_8dfdd_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8dfdd_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_8dfdd_row1_col1\" class=\"data row1 col1\" >Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8dfdd_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_8dfdd_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8dfdd_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_8dfdd_row3_col1\" class=\"data row3 col1\" >(70692, 22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8dfdd_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_8dfdd_row4_col1\" class=\"data row4 col1\" >(68683, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8dfdd_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_8dfdd_row5_col1\" class=\"data row5 col1\" >(47421, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8dfdd_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_8dfdd_row6_col1\" class=\"data row6 col1\" >(21208, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_8dfdd_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_8dfdd_row7_col1\" class=\"data row7 col1\" >21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_8dfdd_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_8dfdd_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_8dfdd_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_8dfdd_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_8dfdd_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_8dfdd_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_8dfdd_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_8dfdd_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_8dfdd_row12_col0\" class=\"data row12 col0\" >Remove multicollinearity</td>\n",
       "      <td id=\"T_8dfdd_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_8dfdd_row13_col0\" class=\"data row13 col0\" >Multicollinearity threshold</td>\n",
       "      <td id=\"T_8dfdd_row13_col1\" class=\"data row13 col1\" >0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_8dfdd_row14_col0\" class=\"data row14 col0\" >Remove outliers</td>\n",
       "      <td id=\"T_8dfdd_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_8dfdd_row15_col0\" class=\"data row15 col0\" >Outliers threshold</td>\n",
       "      <td id=\"T_8dfdd_row15_col1\" class=\"data row15 col1\" >0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_8dfdd_row16_col0\" class=\"data row16 col0\" >Normalize</td>\n",
       "      <td id=\"T_8dfdd_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_8dfdd_row17_col0\" class=\"data row17 col0\" >Normalize method</td>\n",
       "      <td id=\"T_8dfdd_row17_col1\" class=\"data row17 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_8dfdd_row18_col0\" class=\"data row18 col0\" >Feature selection</td>\n",
       "      <td id=\"T_8dfdd_row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_8dfdd_row19_col0\" class=\"data row19 col0\" >Feature selection method</td>\n",
       "      <td id=\"T_8dfdd_row19_col1\" class=\"data row19 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_8dfdd_row20_col0\" class=\"data row20 col0\" >Feature selection estimator</td>\n",
       "      <td id=\"T_8dfdd_row20_col1\" class=\"data row20 col1\" >lightgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_8dfdd_row21_col0\" class=\"data row21 col0\" >Number of features selected</td>\n",
       "      <td id=\"T_8dfdd_row21_col1\" class=\"data row21 col1\" >0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_8dfdd_row22_col0\" class=\"data row22 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_8dfdd_row22_col1\" class=\"data row22 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_8dfdd_row23_col0\" class=\"data row23 col0\" >Fold Number</td>\n",
       "      <td id=\"T_8dfdd_row23_col1\" class=\"data row23 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_8dfdd_row24_col0\" class=\"data row24 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_8dfdd_row24_col1\" class=\"data row24 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_8dfdd_row25_col0\" class=\"data row25 col0\" >Use GPU</td>\n",
       "      <td id=\"T_8dfdd_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_8dfdd_row26_col0\" class=\"data row26 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_8dfdd_row26_col1\" class=\"data row26 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_8dfdd_row27_col0\" class=\"data row27 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_8dfdd_row27_col1\" class=\"data row27 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8dfdd_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_8dfdd_row28_col0\" class=\"data row28 col0\" >USI</td>\n",
       "      <td id=\"T_8dfdd_row28_col1\" class=\"data row28 col1\" >bd08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x134725a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import setup\n",
    "\n",
    "diabetes_experiment = setup(data=data, \n",
    "                            target=\"Diabetes\", \n",
    "                            data_split_stratify=True,\n",
    "                            fix_imbalance=False,\n",
    "                            remove_outliers=True,\n",
    "                            normalize=True,\n",
    "                            feature_selection=True,\n",
    "                            remove_multicollinearity=True,\n",
    "                            session_id=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e0e61",
   "metadata": {},
   "source": [
    "We're telling pycaret that the target column is target=\"Diabetes\". We're also asking the pycaret package to take care of several problems in the dataset. The fix_imbalance parameter tells pycaret to not try to balance the target variable. The remove_outliers parameter tells the package to remove outliers using PCA linear dimensionality reduction. The feature_selection option tells the package to remove unnecessary features from the training set. The remove_multicollinearity option tells the package to drop a feature if it is highly linearly correlated with other features.\n",
    "\n",
    "After analyzing the dataset, we can see that pycaret removed some samples and some columns from the dataset. The original dataset had 70,692 samples, the preprocessed dataset has 68,683 samples. Pycaret also removed features, we had 21 features starting out, after preprocessing only 5 features remained. Pycaret has also added data imputers in the prediction pipeline, we'll use these later to deal with missing values when making predictions.\n",
    "\n",
    "Once pycaret has been setup, we're ready to train some models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "236d5314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_990fb th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_990fb_row0_col0, #T_990fb_row0_col3, #T_990fb_row0_col4, #T_990fb_row1_col0, #T_990fb_row1_col1, #T_990fb_row1_col2, #T_990fb_row1_col4, #T_990fb_row1_col5, #T_990fb_row1_col6, #T_990fb_row1_col7, #T_990fb_row2_col0, #T_990fb_row2_col1, #T_990fb_row2_col2, #T_990fb_row2_col3, #T_990fb_row2_col4, #T_990fb_row2_col5, #T_990fb_row2_col6, #T_990fb_row2_col7, #T_990fb_row3_col0, #T_990fb_row3_col1, #T_990fb_row3_col2, #T_990fb_row3_col3, #T_990fb_row3_col4, #T_990fb_row3_col5, #T_990fb_row3_col6, #T_990fb_row3_col7, #T_990fb_row4_col0, #T_990fb_row4_col1, #T_990fb_row4_col2, #T_990fb_row4_col3, #T_990fb_row4_col4, #T_990fb_row4_col5, #T_990fb_row4_col6, #T_990fb_row4_col7, #T_990fb_row5_col0, #T_990fb_row5_col1, #T_990fb_row5_col2, #T_990fb_row5_col3, #T_990fb_row5_col5, #T_990fb_row5_col6, #T_990fb_row5_col7, #T_990fb_row6_col0, #T_990fb_row6_col1, #T_990fb_row6_col2, #T_990fb_row6_col3, #T_990fb_row6_col4, #T_990fb_row6_col5, #T_990fb_row6_col6, #T_990fb_row6_col7, #T_990fb_row7_col0, #T_990fb_row7_col1, #T_990fb_row7_col2, #T_990fb_row7_col3, #T_990fb_row7_col4, #T_990fb_row7_col5, #T_990fb_row7_col6, #T_990fb_row7_col7, #T_990fb_row8_col0, #T_990fb_row8_col1, #T_990fb_row8_col2, #T_990fb_row8_col3, #T_990fb_row8_col4, #T_990fb_row8_col5, #T_990fb_row8_col6, #T_990fb_row8_col7, #T_990fb_row9_col0, #T_990fb_row9_col1, #T_990fb_row9_col2, #T_990fb_row9_col3, #T_990fb_row9_col4, #T_990fb_row9_col5, #T_990fb_row9_col6, #T_990fb_row9_col7, #T_990fb_row10_col0, #T_990fb_row10_col1, #T_990fb_row10_col2, #T_990fb_row10_col3, #T_990fb_row10_col4, #T_990fb_row10_col5, #T_990fb_row10_col6, #T_990fb_row10_col7, #T_990fb_row11_col0, #T_990fb_row11_col1, #T_990fb_row11_col2, #T_990fb_row11_col3, #T_990fb_row11_col4, #T_990fb_row11_col5, #T_990fb_row11_col6, #T_990fb_row11_col7, #T_990fb_row12_col0, #T_990fb_row12_col1, #T_990fb_row12_col2, #T_990fb_row12_col3, #T_990fb_row12_col4, #T_990fb_row12_col5, #T_990fb_row12_col6, #T_990fb_row12_col7, #T_990fb_row13_col0, #T_990fb_row13_col1, #T_990fb_row13_col2, #T_990fb_row13_col3, #T_990fb_row13_col4, #T_990fb_row13_col5, #T_990fb_row13_col6, #T_990fb_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_990fb_row0_col1, #T_990fb_row0_col2, #T_990fb_row0_col5, #T_990fb_row0_col6, #T_990fb_row0_col7, #T_990fb_row1_col3, #T_990fb_row5_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_990fb_row0_col8, #T_990fb_row1_col8, #T_990fb_row2_col8, #T_990fb_row3_col8, #T_990fb_row4_col8, #T_990fb_row5_col8, #T_990fb_row6_col8, #T_990fb_row7_col8, #T_990fb_row8_col8, #T_990fb_row9_col8, #T_990fb_row10_col8, #T_990fb_row11_col8, #T_990fb_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_990fb_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_990fb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_990fb_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_990fb_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_990fb_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_990fb_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_990fb_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_990fb_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_990fb_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_990fb_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_990fb_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row0\" class=\"row_heading level0 row0\" >gbc</th>\n",
       "      <td id=\"T_990fb_row0_col0\" class=\"data row0 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_990fb_row0_col1\" class=\"data row0 col1\" >0.7318</td>\n",
       "      <td id=\"T_990fb_row0_col2\" class=\"data row0 col2\" >0.8069</td>\n",
       "      <td id=\"T_990fb_row0_col3\" class=\"data row0 col3\" >0.7818</td>\n",
       "      <td id=\"T_990fb_row0_col4\" class=\"data row0 col4\" >0.7108</td>\n",
       "      <td id=\"T_990fb_row0_col5\" class=\"data row0 col5\" >0.7446</td>\n",
       "      <td id=\"T_990fb_row0_col6\" class=\"data row0 col6\" >0.4636</td>\n",
       "      <td id=\"T_990fb_row0_col7\" class=\"data row0 col7\" >0.4660</td>\n",
       "      <td id=\"T_990fb_row0_col8\" class=\"data row0 col8\" >0.6810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_990fb_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_990fb_row1_col1\" class=\"data row1 col1\" >0.7313</td>\n",
       "      <td id=\"T_990fb_row1_col2\" class=\"data row1 col2\" >0.8056</td>\n",
       "      <td id=\"T_990fb_row1_col3\" class=\"data row1 col3\" >0.7823</td>\n",
       "      <td id=\"T_990fb_row1_col4\" class=\"data row1 col4\" >0.7100</td>\n",
       "      <td id=\"T_990fb_row1_col5\" class=\"data row1 col5\" >0.7444</td>\n",
       "      <td id=\"T_990fb_row1_col6\" class=\"data row1 col6\" >0.4627</td>\n",
       "      <td id=\"T_990fb_row1_col7\" class=\"data row1 col7\" >0.4652</td>\n",
       "      <td id=\"T_990fb_row1_col8\" class=\"data row1 col8\" >0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row2\" class=\"row_heading level0 row2\" >ada</th>\n",
       "      <td id=\"T_990fb_row2_col0\" class=\"data row2 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_990fb_row2_col1\" class=\"data row2 col1\" >0.7309</td>\n",
       "      <td id=\"T_990fb_row2_col2\" class=\"data row2 col2\" >0.8053</td>\n",
       "      <td id=\"T_990fb_row2_col3\" class=\"data row2 col3\" >0.7616</td>\n",
       "      <td id=\"T_990fb_row2_col4\" class=\"data row2 col4\" >0.7176</td>\n",
       "      <td id=\"T_990fb_row2_col5\" class=\"data row2 col5\" >0.7389</td>\n",
       "      <td id=\"T_990fb_row2_col6\" class=\"data row2 col6\" >0.4618</td>\n",
       "      <td id=\"T_990fb_row2_col7\" class=\"data row2 col7\" >0.4627</td>\n",
       "      <td id=\"T_990fb_row2_col8\" class=\"data row2 col8\" >0.3710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row3\" class=\"row_heading level0 row3\" >ridge</th>\n",
       "      <td id=\"T_990fb_row3_col0\" class=\"data row3 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_990fb_row3_col1\" class=\"data row3 col1\" >0.7281</td>\n",
       "      <td id=\"T_990fb_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row3_col3\" class=\"data row3 col3\" >0.7444</td>\n",
       "      <td id=\"T_990fb_row3_col4\" class=\"data row3 col4\" >0.7210</td>\n",
       "      <td id=\"T_990fb_row3_col5\" class=\"data row3 col5\" >0.7325</td>\n",
       "      <td id=\"T_990fb_row3_col6\" class=\"data row3 col6\" >0.4562</td>\n",
       "      <td id=\"T_990fb_row3_col7\" class=\"data row3 col7\" >0.4565</td>\n",
       "      <td id=\"T_990fb_row3_col8\" class=\"data row3 col8\" >0.1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row4\" class=\"row_heading level0 row4\" >lda</th>\n",
       "      <td id=\"T_990fb_row4_col0\" class=\"data row4 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_990fb_row4_col1\" class=\"data row4 col1\" >0.7281</td>\n",
       "      <td id=\"T_990fb_row4_col2\" class=\"data row4 col2\" >0.8007</td>\n",
       "      <td id=\"T_990fb_row4_col3\" class=\"data row4 col3\" >0.7444</td>\n",
       "      <td id=\"T_990fb_row4_col4\" class=\"data row4 col4\" >0.7210</td>\n",
       "      <td id=\"T_990fb_row4_col5\" class=\"data row4 col5\" >0.7325</td>\n",
       "      <td id=\"T_990fb_row4_col6\" class=\"data row4 col6\" >0.4562</td>\n",
       "      <td id=\"T_990fb_row4_col7\" class=\"data row4 col7\" >0.4565</td>\n",
       "      <td id=\"T_990fb_row4_col8\" class=\"data row4 col8\" >0.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_990fb_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_990fb_row5_col1\" class=\"data row5 col1\" >0.7279</td>\n",
       "      <td id=\"T_990fb_row5_col2\" class=\"data row5 col2\" >0.8015</td>\n",
       "      <td id=\"T_990fb_row5_col3\" class=\"data row5 col3\" >0.7409</td>\n",
       "      <td id=\"T_990fb_row5_col4\" class=\"data row5 col4\" >0.7222</td>\n",
       "      <td id=\"T_990fb_row5_col5\" class=\"data row5 col5\" >0.7314</td>\n",
       "      <td id=\"T_990fb_row5_col6\" class=\"data row5 col6\" >0.4559</td>\n",
       "      <td id=\"T_990fb_row5_col7\" class=\"data row5 col7\" >0.4561</td>\n",
       "      <td id=\"T_990fb_row5_col8\" class=\"data row5 col8\" >1.6740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row6\" class=\"row_heading level0 row6\" >svm</th>\n",
       "      <td id=\"T_990fb_row6_col0\" class=\"data row6 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_990fb_row6_col1\" class=\"data row6 col1\" >0.7265</td>\n",
       "      <td id=\"T_990fb_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row6_col3\" class=\"data row6 col3\" >0.7552</td>\n",
       "      <td id=\"T_990fb_row6_col4\" class=\"data row6 col4\" >0.7148</td>\n",
       "      <td id=\"T_990fb_row6_col5\" class=\"data row6 col5\" >0.7338</td>\n",
       "      <td id=\"T_990fb_row6_col6\" class=\"data row6 col6\" >0.4529</td>\n",
       "      <td id=\"T_990fb_row6_col7\" class=\"data row6 col7\" >0.4545</td>\n",
       "      <td id=\"T_990fb_row6_col8\" class=\"data row6 col8\" >0.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_990fb_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_990fb_row7_col1\" class=\"data row7 col1\" >0.7265</td>\n",
       "      <td id=\"T_990fb_row7_col2\" class=\"data row7 col2\" >0.7940</td>\n",
       "      <td id=\"T_990fb_row7_col3\" class=\"data row7 col3\" >0.7610</td>\n",
       "      <td id=\"T_990fb_row7_col4\" class=\"data row7 col4\" >0.7119</td>\n",
       "      <td id=\"T_990fb_row7_col5\" class=\"data row7 col5\" >0.7356</td>\n",
       "      <td id=\"T_990fb_row7_col6\" class=\"data row7 col6\" >0.4530</td>\n",
       "      <td id=\"T_990fb_row7_col7\" class=\"data row7 col7\" >0.4541</td>\n",
       "      <td id=\"T_990fb_row7_col8\" class=\"data row7 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row8\" class=\"row_heading level0 row8\" >nb</th>\n",
       "      <td id=\"T_990fb_row8_col0\" class=\"data row8 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_990fb_row8_col1\" class=\"data row8 col1\" >0.7210</td>\n",
       "      <td id=\"T_990fb_row8_col2\" class=\"data row8 col2\" >0.7939</td>\n",
       "      <td id=\"T_990fb_row8_col3\" class=\"data row8 col3\" >0.7207</td>\n",
       "      <td id=\"T_990fb_row8_col4\" class=\"data row8 col4\" >0.7212</td>\n",
       "      <td id=\"T_990fb_row8_col5\" class=\"data row8 col5\" >0.7209</td>\n",
       "      <td id=\"T_990fb_row8_col6\" class=\"data row8 col6\" >0.4420</td>\n",
       "      <td id=\"T_990fb_row8_col7\" class=\"data row8 col7\" >0.4420</td>\n",
       "      <td id=\"T_990fb_row8_col8\" class=\"data row8 col8\" >0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row9\" class=\"row_heading level0 row9\" >rf</th>\n",
       "      <td id=\"T_990fb_row9_col0\" class=\"data row9 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_990fb_row9_col1\" class=\"data row9 col1\" >0.7001</td>\n",
       "      <td id=\"T_990fb_row9_col2\" class=\"data row9 col2\" >0.7617</td>\n",
       "      <td id=\"T_990fb_row9_col3\" class=\"data row9 col3\" >0.7204</td>\n",
       "      <td id=\"T_990fb_row9_col4\" class=\"data row9 col4\" >0.6923</td>\n",
       "      <td id=\"T_990fb_row9_col5\" class=\"data row9 col5\" >0.7061</td>\n",
       "      <td id=\"T_990fb_row9_col6\" class=\"data row9 col6\" >0.4002</td>\n",
       "      <td id=\"T_990fb_row9_col7\" class=\"data row9 col7\" >0.4006</td>\n",
       "      <td id=\"T_990fb_row9_col8\" class=\"data row9 col8\" >1.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row10\" class=\"row_heading level0 row10\" >knn</th>\n",
       "      <td id=\"T_990fb_row10_col0\" class=\"data row10 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_990fb_row10_col1\" class=\"data row10 col1\" >0.6942</td>\n",
       "      <td id=\"T_990fb_row10_col2\" class=\"data row10 col2\" >0.7485</td>\n",
       "      <td id=\"T_990fb_row10_col3\" class=\"data row10 col3\" >0.7166</td>\n",
       "      <td id=\"T_990fb_row10_col4\" class=\"data row10 col4\" >0.6859</td>\n",
       "      <td id=\"T_990fb_row10_col5\" class=\"data row10 col5\" >0.7008</td>\n",
       "      <td id=\"T_990fb_row10_col6\" class=\"data row10 col6\" >0.3883</td>\n",
       "      <td id=\"T_990fb_row10_col7\" class=\"data row10 col7\" >0.3888</td>\n",
       "      <td id=\"T_990fb_row10_col8\" class=\"data row10 col8\" >0.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row11\" class=\"row_heading level0 row11\" >et</th>\n",
       "      <td id=\"T_990fb_row11_col0\" class=\"data row11 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_990fb_row11_col1\" class=\"data row11 col1\" >0.6900</td>\n",
       "      <td id=\"T_990fb_row11_col2\" class=\"data row11 col2\" >0.7467</td>\n",
       "      <td id=\"T_990fb_row11_col3\" class=\"data row11 col3\" >0.6760</td>\n",
       "      <td id=\"T_990fb_row11_col4\" class=\"data row11 col4\" >0.6955</td>\n",
       "      <td id=\"T_990fb_row11_col5\" class=\"data row11 col5\" >0.6856</td>\n",
       "      <td id=\"T_990fb_row11_col6\" class=\"data row11 col6\" >0.3800</td>\n",
       "      <td id=\"T_990fb_row11_col7\" class=\"data row11 col7\" >0.3802</td>\n",
       "      <td id=\"T_990fb_row11_col8\" class=\"data row11 col8\" >1.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row12\" class=\"row_heading level0 row12\" >dt</th>\n",
       "      <td id=\"T_990fb_row12_col0\" class=\"data row12 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_990fb_row12_col1\" class=\"data row12 col1\" >0.6867</td>\n",
       "      <td id=\"T_990fb_row12_col2\" class=\"data row12 col2\" >0.7368</td>\n",
       "      <td id=\"T_990fb_row12_col3\" class=\"data row12 col3\" >0.6688</td>\n",
       "      <td id=\"T_990fb_row12_col4\" class=\"data row12 col4\" >0.6937</td>\n",
       "      <td id=\"T_990fb_row12_col5\" class=\"data row12 col5\" >0.6810</td>\n",
       "      <td id=\"T_990fb_row12_col6\" class=\"data row12 col6\" >0.3735</td>\n",
       "      <td id=\"T_990fb_row12_col7\" class=\"data row12 col7\" >0.3738</td>\n",
       "      <td id=\"T_990fb_row12_col8\" class=\"data row12 col8\" >0.1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_990fb_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_990fb_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_990fb_row13_col1\" class=\"data row13 col1\" >0.5000</td>\n",
       "      <td id=\"T_990fb_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_990fb_row13_col3\" class=\"data row13 col3\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row13_col4\" class=\"data row13 col4\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row13_col5\" class=\"data row13 col5\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_990fb_row13_col8\" class=\"data row13 col8\" >0.0890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x133fcae50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import compare_models\n",
    "\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e3ddd",
   "metadata": {},
   "source": [
    "The function displays a table of the model metrics, highlighting the models with the highest metrics in each category. The function also returns the best model found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d923b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=42, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1a6ea",
   "metadata": {},
   "source": [
    "In this case, pycaret returned the GradientBoostingClassifier as the best model. The model selected has the highest accuracy, AUC, recall, and F1 score, but does not have the highest precision. This first step is only to get an idea of the way the different types of models perform on the problem. We'll need to choose among the models for the one that meets our requirements. \n",
    "\n",
    "There are other things to take into account when selecting a model. For example, certain models take a lot more memory and CPU time to make predictions. In certain situations, it would be better to select a model with lower accuracy but that is able to meet the requirements of the deployment environment.\n",
    "\n",
    "It looks like the Gradient Boosting Classifier model has the highest F1 score, while also having a high accuracy. So we'll select it to keep working with. To train a gbc model, we'll call the pycaret create_model() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3276e488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_95af0_row10_col0, #T_95af0_row10_col1, #T_95af0_row10_col2, #T_95af0_row10_col3, #T_95af0_row10_col4, #T_95af0_row10_col5, #T_95af0_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_95af0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_95af0_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_95af0_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_95af0_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_95af0_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_95af0_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_95af0_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_95af0_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_95af0_row0_col0\" class=\"data row0 col0\" >0.7264</td>\n",
       "      <td id=\"T_95af0_row0_col1\" class=\"data row0 col1\" >0.8041</td>\n",
       "      <td id=\"T_95af0_row0_col2\" class=\"data row0 col2\" >0.7770</td>\n",
       "      <td id=\"T_95af0_row0_col3\" class=\"data row0 col3\" >0.7057</td>\n",
       "      <td id=\"T_95af0_row0_col4\" class=\"data row0 col4\" >0.7396</td>\n",
       "      <td id=\"T_95af0_row0_col5\" class=\"data row0 col5\" >0.4528</td>\n",
       "      <td id=\"T_95af0_row0_col6\" class=\"data row0 col6\" >0.4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_95af0_row1_col0\" class=\"data row1 col0\" >0.7367</td>\n",
       "      <td id=\"T_95af0_row1_col1\" class=\"data row1 col1\" >0.8050</td>\n",
       "      <td id=\"T_95af0_row1_col2\" class=\"data row1 col2\" >0.7907</td>\n",
       "      <td id=\"T_95af0_row1_col3\" class=\"data row1 col3\" >0.7137</td>\n",
       "      <td id=\"T_95af0_row1_col4\" class=\"data row1 col4\" >0.7502</td>\n",
       "      <td id=\"T_95af0_row1_col5\" class=\"data row1 col5\" >0.4734</td>\n",
       "      <td id=\"T_95af0_row1_col6\" class=\"data row1 col6\" >0.4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_95af0_row2_col0\" class=\"data row2 col0\" >0.7298</td>\n",
       "      <td id=\"T_95af0_row2_col1\" class=\"data row2 col1\" >0.8048</td>\n",
       "      <td id=\"T_95af0_row2_col2\" class=\"data row2 col2\" >0.7684</td>\n",
       "      <td id=\"T_95af0_row2_col3\" class=\"data row2 col3\" >0.7133</td>\n",
       "      <td id=\"T_95af0_row2_col4\" class=\"data row2 col4\" >0.7398</td>\n",
       "      <td id=\"T_95af0_row2_col5\" class=\"data row2 col5\" >0.4597</td>\n",
       "      <td id=\"T_95af0_row2_col6\" class=\"data row2 col6\" >0.4611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_95af0_row3_col0\" class=\"data row3 col0\" >0.7357</td>\n",
       "      <td id=\"T_95af0_row3_col1\" class=\"data row3 col1\" >0.8053</td>\n",
       "      <td id=\"T_95af0_row3_col2\" class=\"data row3 col2\" >0.7979</td>\n",
       "      <td id=\"T_95af0_row3_col3\" class=\"data row3 col3\" >0.7096</td>\n",
       "      <td id=\"T_95af0_row3_col4\" class=\"data row3 col4\" >0.7511</td>\n",
       "      <td id=\"T_95af0_row3_col5\" class=\"data row3 col5\" >0.4714</td>\n",
       "      <td id=\"T_95af0_row3_col6\" class=\"data row3 col6\" >0.4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_95af0_row4_col0\" class=\"data row4 col0\" >0.7318</td>\n",
       "      <td id=\"T_95af0_row4_col1\" class=\"data row4 col1\" >0.8098</td>\n",
       "      <td id=\"T_95af0_row4_col2\" class=\"data row4 col2\" >0.7765</td>\n",
       "      <td id=\"T_95af0_row4_col3\" class=\"data row4 col3\" >0.7128</td>\n",
       "      <td id=\"T_95af0_row4_col4\" class=\"data row4 col4\" >0.7433</td>\n",
       "      <td id=\"T_95af0_row4_col5\" class=\"data row4 col5\" >0.4636</td>\n",
       "      <td id=\"T_95af0_row4_col6\" class=\"data row4 col6\" >0.4655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_95af0_row5_col0\" class=\"data row5 col0\" >0.7314</td>\n",
       "      <td id=\"T_95af0_row5_col1\" class=\"data row5 col1\" >0.8075</td>\n",
       "      <td id=\"T_95af0_row5_col2\" class=\"data row5 col2\" >0.7765</td>\n",
       "      <td id=\"T_95af0_row5_col3\" class=\"data row5 col3\" >0.7123</td>\n",
       "      <td id=\"T_95af0_row5_col4\" class=\"data row5 col4\" >0.7430</td>\n",
       "      <td id=\"T_95af0_row5_col5\" class=\"data row5 col5\" >0.4628</td>\n",
       "      <td id=\"T_95af0_row5_col6\" class=\"data row5 col6\" >0.4647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_95af0_row6_col0\" class=\"data row6 col0\" >0.7268</td>\n",
       "      <td id=\"T_95af0_row6_col1\" class=\"data row6 col1\" >0.7999</td>\n",
       "      <td id=\"T_95af0_row6_col2\" class=\"data row6 col2\" >0.7817</td>\n",
       "      <td id=\"T_95af0_row6_col3\" class=\"data row6 col3\" >0.7043</td>\n",
       "      <td id=\"T_95af0_row6_col4\" class=\"data row6 col4\" >0.7410</td>\n",
       "      <td id=\"T_95af0_row6_col5\" class=\"data row6 col5\" >0.4535</td>\n",
       "      <td id=\"T_95af0_row6_col6\" class=\"data row6 col6\" >0.4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_95af0_row7_col0\" class=\"data row7 col0\" >0.7357</td>\n",
       "      <td id=\"T_95af0_row7_col1\" class=\"data row7 col1\" >0.8104</td>\n",
       "      <td id=\"T_95af0_row7_col2\" class=\"data row7 col2\" >0.7890</td>\n",
       "      <td id=\"T_95af0_row7_col3\" class=\"data row7 col3\" >0.7129</td>\n",
       "      <td id=\"T_95af0_row7_col4\" class=\"data row7 col4\" >0.7490</td>\n",
       "      <td id=\"T_95af0_row7_col5\" class=\"data row7 col5\" >0.4713</td>\n",
       "      <td id=\"T_95af0_row7_col6\" class=\"data row7 col6\" >0.4740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_95af0_row8_col0\" class=\"data row8 col0\" >0.7310</td>\n",
       "      <td id=\"T_95af0_row8_col1\" class=\"data row8 col1\" >0.8060</td>\n",
       "      <td id=\"T_95af0_row8_col2\" class=\"data row8 col2\" >0.7789</td>\n",
       "      <td id=\"T_95af0_row8_col3\" class=\"data row8 col3\" >0.7108</td>\n",
       "      <td id=\"T_95af0_row8_col4\" class=\"data row8 col4\" >0.7433</td>\n",
       "      <td id=\"T_95af0_row8_col5\" class=\"data row8 col5\" >0.4620</td>\n",
       "      <td id=\"T_95af0_row8_col6\" class=\"data row8 col6\" >0.4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_95af0_row9_col0\" class=\"data row9 col0\" >0.7328</td>\n",
       "      <td id=\"T_95af0_row9_col1\" class=\"data row9 col1\" >0.8164</td>\n",
       "      <td id=\"T_95af0_row9_col2\" class=\"data row9 col2\" >0.7813</td>\n",
       "      <td id=\"T_95af0_row9_col3\" class=\"data row9 col3\" >0.7122</td>\n",
       "      <td id=\"T_95af0_row9_col4\" class=\"data row9 col4\" >0.7452</td>\n",
       "      <td id=\"T_95af0_row9_col5\" class=\"data row9 col5\" >0.4656</td>\n",
       "      <td id=\"T_95af0_row9_col6\" class=\"data row9 col6\" >0.4678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_95af0_row10_col0\" class=\"data row10 col0\" >0.7318</td>\n",
       "      <td id=\"T_95af0_row10_col1\" class=\"data row10 col1\" >0.8069</td>\n",
       "      <td id=\"T_95af0_row10_col2\" class=\"data row10 col2\" >0.7818</td>\n",
       "      <td id=\"T_95af0_row10_col3\" class=\"data row10 col3\" >0.7108</td>\n",
       "      <td id=\"T_95af0_row10_col4\" class=\"data row10 col4\" >0.7446</td>\n",
       "      <td id=\"T_95af0_row10_col5\" class=\"data row10 col5\" >0.4636</td>\n",
       "      <td id=\"T_95af0_row10_col6\" class=\"data row10 col6\" >0.4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_95af0_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_95af0_row11_col0\" class=\"data row11 col0\" >0.0034</td>\n",
       "      <td id=\"T_95af0_row11_col1\" class=\"data row11 col1\" >0.0042</td>\n",
       "      <td id=\"T_95af0_row11_col2\" class=\"data row11 col2\" >0.0081</td>\n",
       "      <td id=\"T_95af0_row11_col3\" class=\"data row11 col3\" >0.0031</td>\n",
       "      <td id=\"T_95af0_row11_col4\" class=\"data row11 col4\" >0.0040</td>\n",
       "      <td id=\"T_95af0_row11_col5\" class=\"data row11 col5\" >0.0068</td>\n",
       "      <td id=\"T_95af0_row11_col6\" class=\"data row11 col6\" >0.0070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12d3548b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.classification import create_model\n",
    "\n",
    "model = create_model(\"gbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301188e",
   "metadata": {},
   "source": [
    "Once the model has been created, we can do hyperparameter tuning with the tune_model() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f98566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0a20_row10_col0, #T_c0a20_row10_col1, #T_c0a20_row10_col2, #T_c0a20_row10_col3, #T_c0a20_row10_col4, #T_c0a20_row10_col5, #T_c0a20_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0a20\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c0a20_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c0a20_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_c0a20_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_c0a20_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_c0a20_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_c0a20_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_c0a20_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c0a20_row0_col0\" class=\"data row0 col0\" >0.7296</td>\n",
       "      <td id=\"T_c0a20_row0_col1\" class=\"data row0 col1\" >0.8041</td>\n",
       "      <td id=\"T_c0a20_row0_col2\" class=\"data row0 col2\" >0.7826</td>\n",
       "      <td id=\"T_c0a20_row0_col3\" class=\"data row0 col3\" >0.7077</td>\n",
       "      <td id=\"T_c0a20_row0_col4\" class=\"data row0 col4\" >0.7433</td>\n",
       "      <td id=\"T_c0a20_row0_col5\" class=\"data row0 col5\" >0.4593</td>\n",
       "      <td id=\"T_c0a20_row0_col6\" class=\"data row0 col6\" >0.4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c0a20_row1_col0\" class=\"data row1 col0\" >0.7377</td>\n",
       "      <td id=\"T_c0a20_row1_col1\" class=\"data row1 col1\" >0.8051</td>\n",
       "      <td id=\"T_c0a20_row1_col2\" class=\"data row1 col2\" >0.7952</td>\n",
       "      <td id=\"T_c0a20_row1_col3\" class=\"data row1 col3\" >0.7133</td>\n",
       "      <td id=\"T_c0a20_row1_col4\" class=\"data row1 col4\" >0.7520</td>\n",
       "      <td id=\"T_c0a20_row1_col5\" class=\"data row1 col5\" >0.4754</td>\n",
       "      <td id=\"T_c0a20_row1_col6\" class=\"data row1 col6\" >0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c0a20_row2_col0\" class=\"data row2 col0\" >0.7254</td>\n",
       "      <td id=\"T_c0a20_row2_col1\" class=\"data row2 col1\" >0.8024</td>\n",
       "      <td id=\"T_c0a20_row2_col2\" class=\"data row2 col2\" >0.7668</td>\n",
       "      <td id=\"T_c0a20_row2_col3\" class=\"data row2 col3\" >0.7081</td>\n",
       "      <td id=\"T_c0a20_row2_col4\" class=\"data row2 col4\" >0.7363</td>\n",
       "      <td id=\"T_c0a20_row2_col5\" class=\"data row2 col5\" >0.4508</td>\n",
       "      <td id=\"T_c0a20_row2_col6\" class=\"data row2 col6\" >0.4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c0a20_row3_col0\" class=\"data row3 col0\" >0.7341</td>\n",
       "      <td id=\"T_c0a20_row3_col1\" class=\"data row3 col1\" >0.8054</td>\n",
       "      <td id=\"T_c0a20_row3_col2\" class=\"data row3 col2\" >0.7971</td>\n",
       "      <td id=\"T_c0a20_row3_col3\" class=\"data row3 col3\" >0.7078</td>\n",
       "      <td id=\"T_c0a20_row3_col4\" class=\"data row3 col4\" >0.7498</td>\n",
       "      <td id=\"T_c0a20_row3_col5\" class=\"data row3 col5\" >0.4682</td>\n",
       "      <td id=\"T_c0a20_row3_col6\" class=\"data row3 col6\" >0.4720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c0a20_row4_col0\" class=\"data row4 col0\" >0.7316</td>\n",
       "      <td id=\"T_c0a20_row4_col1\" class=\"data row4 col1\" >0.8088</td>\n",
       "      <td id=\"T_c0a20_row4_col2\" class=\"data row4 col2\" >0.7736</td>\n",
       "      <td id=\"T_c0a20_row4_col3\" class=\"data row4 col3\" >0.7136</td>\n",
       "      <td id=\"T_c0a20_row4_col4\" class=\"data row4 col4\" >0.7424</td>\n",
       "      <td id=\"T_c0a20_row4_col5\" class=\"data row4 col5\" >0.4632</td>\n",
       "      <td id=\"T_c0a20_row4_col6\" class=\"data row4 col6\" >0.4649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c0a20_row5_col0\" class=\"data row5 col0\" >0.7357</td>\n",
       "      <td id=\"T_c0a20_row5_col1\" class=\"data row5 col1\" >0.8055</td>\n",
       "      <td id=\"T_c0a20_row5_col2\" class=\"data row5 col2\" >0.7793</td>\n",
       "      <td id=\"T_c0a20_row5_col3\" class=\"data row5 col3\" >0.7167</td>\n",
       "      <td id=\"T_c0a20_row5_col4\" class=\"data row5 col4\" >0.7467</td>\n",
       "      <td id=\"T_c0a20_row5_col5\" class=\"data row5 col5\" >0.4713</td>\n",
       "      <td id=\"T_c0a20_row5_col6\" class=\"data row5 col6\" >0.4731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c0a20_row6_col0\" class=\"data row6 col0\" >0.7241</td>\n",
       "      <td id=\"T_c0a20_row6_col1\" class=\"data row6 col1\" >0.7996</td>\n",
       "      <td id=\"T_c0a20_row6_col2\" class=\"data row6 col2\" >0.7805</td>\n",
       "      <td id=\"T_c0a20_row6_col3\" class=\"data row6 col3\" >0.7014</td>\n",
       "      <td id=\"T_c0a20_row6_col4\" class=\"data row6 col4\" >0.7389</td>\n",
       "      <td id=\"T_c0a20_row6_col5\" class=\"data row6 col5\" >0.4483</td>\n",
       "      <td id=\"T_c0a20_row6_col6\" class=\"data row6 col6\" >0.4511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c0a20_row7_col0\" class=\"data row7 col0\" >0.7411</td>\n",
       "      <td id=\"T_c0a20_row7_col1\" class=\"data row7 col1\" >0.8086</td>\n",
       "      <td id=\"T_c0a20_row7_col2\" class=\"data row7 col2\" >0.7882</td>\n",
       "      <td id=\"T_c0a20_row7_col3\" class=\"data row7 col3\" >0.7204</td>\n",
       "      <td id=\"T_c0a20_row7_col4\" class=\"data row7 col4\" >0.7528</td>\n",
       "      <td id=\"T_c0a20_row7_col5\" class=\"data row7 col5\" >0.4822</td>\n",
       "      <td id=\"T_c0a20_row7_col6\" class=\"data row7 col6\" >0.4844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c0a20_row8_col0\" class=\"data row8 col0\" >0.7342</td>\n",
       "      <td id=\"T_c0a20_row8_col1\" class=\"data row8 col1\" >0.8055</td>\n",
       "      <td id=\"T_c0a20_row8_col2\" class=\"data row8 col2\" >0.7858</td>\n",
       "      <td id=\"T_c0a20_row8_col3\" class=\"data row8 col3\" >0.7123</td>\n",
       "      <td id=\"T_c0a20_row8_col4\" class=\"data row8 col4\" >0.7473</td>\n",
       "      <td id=\"T_c0a20_row8_col5\" class=\"data row8 col5\" >0.4685</td>\n",
       "      <td id=\"T_c0a20_row8_col6\" class=\"data row8 col6\" >0.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c0a20_row9_col0\" class=\"data row9 col0\" >0.7330</td>\n",
       "      <td id=\"T_c0a20_row9_col1\" class=\"data row9 col1\" >0.8149</td>\n",
       "      <td id=\"T_c0a20_row9_col2\" class=\"data row9 col2\" >0.7789</td>\n",
       "      <td id=\"T_c0a20_row9_col3\" class=\"data row9 col3\" >0.7134</td>\n",
       "      <td id=\"T_c0a20_row9_col4\" class=\"data row9 col4\" >0.7447</td>\n",
       "      <td id=\"T_c0a20_row9_col5\" class=\"data row9 col5\" >0.4660</td>\n",
       "      <td id=\"T_c0a20_row9_col6\" class=\"data row9 col6\" >0.4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_c0a20_row10_col0\" class=\"data row10 col0\" >0.7327</td>\n",
       "      <td id=\"T_c0a20_row10_col1\" class=\"data row10 col1\" >0.8060</td>\n",
       "      <td id=\"T_c0a20_row10_col2\" class=\"data row10 col2\" >0.7828</td>\n",
       "      <td id=\"T_c0a20_row10_col3\" class=\"data row10 col3\" >0.7115</td>\n",
       "      <td id=\"T_c0a20_row10_col4\" class=\"data row10 col4\" >0.7454</td>\n",
       "      <td id=\"T_c0a20_row10_col5\" class=\"data row10 col5\" >0.4653</td>\n",
       "      <td id=\"T_c0a20_row10_col6\" class=\"data row10 col6\" >0.4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0a20_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_c0a20_row11_col0\" class=\"data row11 col0\" >0.0050</td>\n",
       "      <td id=\"T_c0a20_row11_col1\" class=\"data row11 col1\" >0.0039</td>\n",
       "      <td id=\"T_c0a20_row11_col2\" class=\"data row11 col2\" >0.0088</td>\n",
       "      <td id=\"T_c0a20_row11_col3\" class=\"data row11 col3\" >0.0051</td>\n",
       "      <td id=\"T_c0a20_row11_col4\" class=\"data row11 col4\" >0.0051</td>\n",
       "      <td id=\"T_c0a20_row11_col5\" class=\"data row11 col5\" >0.0099</td>\n",
       "      <td id=\"T_c0a20_row11_col6\" class=\"data row11 col6\" >0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12e2af1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import tune_model\n",
    "\n",
    "tuned_model = tune_model(model, n_iter=10, optimize=\"F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ade00",
   "metadata": {},
   "source": [
    "We asked pycaret to maximize the F1 score of the model. By tuning the hyperameters, we were able to raise the F1 score from 0.7446 to 0.7454. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde081f8",
   "metadata": {},
   "source": [
    "## Validating the Model\n",
    "\n",
    "Pycaret is integrated with the [yellowbrick package](https://www.scikit-yb.org/en/latest/) for creating visualizations. We can easily generate many standard plots to show the performance of our model.\n",
    "\n",
    "The area under the curve plot can be generated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b979bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import plot_model\n",
    "\n",
    "plot_model(tuned_model, plot=\"auc\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608aadb",
   "metadata": {},
   "source": [
    "![AUC](auc_sdfmlm.png)\n",
    "![AUC]({attach}auc_sdfmlm.png){ width=50% }\n",
    "\n",
    "The AUC plot is useful for understanding the tradeoffs between the true positive rate and the false positive rate of the model's predictions.\n",
    "\n",
    "The confusion matrix can be plotted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00554ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_model, plot=\"confusion_matrix\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03ccc7",
   "metadata": {},
   "source": [
    "![Confusion Matrix](confusion_matrix_sdfmlm.png)\n",
    "![Confusion Matrix]({attach}confusion_matrix_sdfmlm.png){ width=50% }\n",
    "\n",
    "The confusion matrix is useful for understanding which classes are being \"confused\" for each other by the model. The confusion matrix shows how many predictions were correctly and incorrectly made for each combination of classes.\n",
    "\n",
    "The classification report can be plotted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de090234",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_model(tuned_model, plot=\"class_report\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf72ae0",
   "metadata": {},
   "source": [
    "![Classification Report](class_report_sdfmlm.png)\n",
    "![Classification Report]({attach}class_report_sdfmlm.png){ width=50% }\n",
    "\n",
    "The classification report shows the precision, recall, F1, and support metrics of the model for each class.\n",
    "\n",
    "The class prediction error can be plotted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2363e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_model(tuned_model, plot=\"error\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53506e",
   "metadata": {},
   "source": [
    "![Class Prediction Error](prediction_error_sdfmlm.png)\n",
    "![Class Prediction Error]({attach}prediction_error_sdfmlm.png){ width=50% }\n",
    "\n",
    "The class prediction error is similar to the classification report and confusion matrix, but highlights the per-class prediction error of the model.\n",
    "\n",
    "The feature importance can be plotted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c16b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_model(tuned_model, plot=\"feature\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246b432",
   "metadata": {},
   "source": [
    "![Feature Importance](feature_importance_sdfmlm.png)\n",
    "![Feature Importance]({attach}feature_importance_sdfmlm.png){ width=50% }\n",
    "\n",
    "The feature importance plot is for understanding which features are most useful for making accurate predictions.\n",
    "\n",
    "The learning curve can be plotted like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98ab5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plot_model(tuned_model, plot=\"learning\", save=True)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ee11b",
   "metadata": {},
   "source": [
    "![Learning Curve](learning_curve_sdfmlm.png)\n",
    "![Learning Curve]({attach}learning_curve_sdfmlm.png){ width=50% }\n",
    "\n",
    "The learning curve shows how the quality of the model varies when tested with the training set and the validation set, when using a varying number of training samples. This is useful for showing whether the model is underfit or overfit on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2354e",
   "metadata": {},
   "source": [
    "## Finalizing the Model\n",
    "\n",
    "Once we have a tuned and validated model, we can use the entire dataset to train it again, in order to leverage the data samples that were held out for the testing and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cacfda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import finalize_model\n",
    "\n",
    "finalized_model = finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3bcba8",
   "metadata": {},
   "source": [
    "Now that we have a trained, validated, and finalized model, we'll save it disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e218819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../diabetes_risk_model/model_files/model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(finalized_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13b51b",
   "metadata": {},
   "source": [
    "## Signing the Model Parameters\n",
    "\n",
    "Once we have the model parameters saved as a pickle file, we can sign the model parameters cryptographically. Signing the model parameters will enable us to ensure that the bytes that we are saving are exactly the same bytes that will be used to make predictions. The process involves creating a \"signature\" for the model parameters, and later verifying the signature.\n",
    "\n",
    "To sign the model parameters we'll use the [itsdangerous package](https://itsdangerous.palletsprojects.com/en/2.1.x/). This package is useful for sending data through untrusted channels, where there is a chance that an attacker can modify the data.\n",
    "\n",
    "Let's install the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa49ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install itsdangerous\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d450348",
   "metadata": {},
   "source": [
    "Signing messages requires that we come up with a secret key that is only known to us. We'll create a key and store it in a string variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d597de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wjtRFppXQpxTChQnNcQJKGlLHKJBmAHMepfFbqvOoUrnuxIsKdiLCrrypYFQsqcw'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import secrets\n",
    "import string\n",
    "\n",
    "secret_key = \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for _ in range(64))\n",
    "secret_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba13997",
   "metadata": {},
   "source": [
    "Next, we'll load the model parameters that we just saved into a bytes object so that we can sign them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e10d53e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../diabetes_risk_model/model_files/model.pkl\", \"rb\") as file:\n",
    "    model_bytes = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c261ee",
   "metadata": {},
   "source": [
    "The signing process looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ee05caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itsdangerous import Signer\n",
    "\n",
    "signer = Signer(secret_key)\n",
    "\n",
    "signed_model_bytes = signer.sign(model_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496868d3",
   "metadata": {},
   "source": [
    "The signed model bytes now have a signature appended to them, which means that the model can't be deserialized using pickle anymore. We have to unsign them to be able to do that. Here is how the unisigning process looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11d413fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsigned_model_bytes = signer.unsign(signed_model_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc4386",
   "metadata": {},
   "source": [
    "The model bytes were verified using the secret key, and the signature was removed from the bytes object. Now we can unpickle the model object as we normally would:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2423ecbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycaret.internal.pipeline.Pipeline"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.loads(model_bytes)\n",
    "\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf1e3d",
   "metadata": {},
   "source": [
    "To show how the process would go if the model bytes were modified, let's add a single byte to the end of the signed bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19580dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_signed_model_bytes = signed_model_bytes + bytes([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43317e",
   "metadata": {},
   "source": [
    "Now let's try to unsign the bytes object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc730f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BadSignature exception raised!\n"
     ]
    }
   ],
   "source": [
    "from itsdangerous import BadSignature\n",
    "\n",
    "try:\n",
    "    signer.unsign(changed_signed_model_bytes)\n",
    "except BadSignature as e:\n",
    "    print(\"BadSignature exception raised!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535f74d",
   "metadata": {},
   "source": [
    "Because the bytes were modified, the unsign method raised an exception.\n",
    "\n",
    "Let's save the signed model bytes to disk, alongside the original model pickle file we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7b55b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../diabetes_risk_model/model_files/signed_model.pkl\", \"wb\") as file:\n",
    "    file.write(signed_model_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa364e9",
   "metadata": {},
   "source": [
    "## Packaging the Model Parameters\n",
    "\n",
    "We now have signed model parameters. In order to deploy them we'll package them together with other results of the training process.\n",
    "\n",
    "The model parameters are in the model_files folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "222e9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11936\r\n",
      "drwxr-xr-x  6 brian  staff      192 Mar 17 23:31 \u001b[34m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  8 brian  staff      256 Feb 25 23:50 \u001b[34m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@ 1 brian  staff     6148 Mar 15 22:40 .DS_Store\r\n",
      "-rw-r--r--@ 1 brian  staff  1261313 Mar 17 22:57 data_report.html\r\n",
      "-rw-r--r--  1 brian  staff  2419848 Mar 17 23:20 model.pkl\r\n",
      "-rw-r--r--  1 brian  staff  2419876 Mar 17 23:31 signed_model.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -la ../diabetes_risk_model/model_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b98df",
   "metadata": {},
   "source": [
    "In the process of training this model, we created a few files containing the descriptive of the training set and other things. We'll save those files alongside the model parameters in a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89f970dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brian/Code/securing-parameters-for-ml-models/diabetes_risk_model/diabetes_risk_model-0.1.0-2023_03_17.zip'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"../diabetes_risk_model/diabetes_risk_model-0.1.0-2023_03_17\", \n",
    "                    \"zip\", \n",
    "                    \"../diabetes_risk_model/model_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69989f66",
   "metadata": {},
   "source": [
    "The command created a .zip file with all of the files in the model_files folder. The name of the zip file has the model name, model version, and today's date in it. This allows us to easily understand what the contents of the zip file are.\n",
    "\n",
    "Now that we have the model files in a .zip file, we can delete the original files from the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6514cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../diabetes_risk_model/model_files/data_report.html\n",
    "!rm ../diabetes_risk_model/model_files/model.pkl\n",
    "!rm ../diabetes_risk_model/model_files/signed_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c93a3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ../diabetes_risk_model/diabetes_risk_model-0.1.0-2023_03_17.zip ../diabetes_risk_model/model_files/diabetes_risk_model-0.1.0-2023_03_17.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7b3db",
   "metadata": {},
   "source": [
    "This packaging process ensures that all of the results of the model training process end up in one archive that we can use later. All of the data and model check results are packaged along with the serialized model so its easy to review the model training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999e85c",
   "metadata": {},
   "source": [
    "## Storing the Model Parameters\n",
    "\n",
    "In order to store the model parameters, we'll be using a local S3 compatible service called [minio](https://min.io/). The minio project replicates the S3 API, and also provides a docker image. \n",
    "\n",
    "To use the minio service, we'll first need a folder to store the files that it will host:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec21c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ../minio_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51362451",
   "metadata": {},
   "source": [
    "To run an instance of minio locally, use this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3baf9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d5283c718b1b1dc8d60eadbc03a2834647088474431c66bd032eab726670c1d7\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    -p 9000:9000 \\\n",
    "    -p 9001:9001 \\\n",
    "    -e \"MINIO_ACCESS_KEY=TEST\" \\\n",
    "    -e \"MINIO_SECRET_KEY=ASDFGHJKL\" \\\n",
    "    --name minio \\\n",
    "    -v $(pwd)/../minio_data:/data \\\n",
    "    quay.io/minio/minio server /data --console-address \":9001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35c604",
   "metadata": {},
   "source": [
    "The minio service instance running in the docker container is accessing the local filesystem to serve files. When minio is running in this way, it makes the folders it finds in the local filesystem available as buckets through its API, in exactly the same API as the AWS S3 service.\n",
    "\n",
    "In order to easily interact with the minio service, we'll use the [minio package](https://pypi.org/project/minio/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7c6cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install minio\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc0158",
   "metadata": {},
   "source": [
    "Let's create a client to connect to the minio service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ebf70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "\n",
    "minio_client = Minio(\"127.0.0.1:9000\",\n",
    "                     access_key='TEST',\n",
    "                     secret_key='ASDFGHJKL',\n",
    "                     secure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc4af5",
   "metadata": {},
   "source": [
    "Let's make a bucket for the model files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b36de9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client.make_bucket(\"model-files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97cbb24",
   "metadata": {},
   "source": [
    "Now let's upload the packaged model parameters to the bucket so that we can make predictions with the model parameters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c4ba34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "with open(\"../diabetes_risk_model/model_files/diabetes_risk_model-0.1.0-2023_03_17.zip\", \"rb\") as file:\n",
    "    zip_bytes = file.read()\n",
    "\n",
    "result = minio_client.put_object(\n",
    "    bucket_name=\"model-files\", \n",
    "    object_name=\"diabetes_risk_model-0.1.0-2023_03_17.zip\", \n",
    "    data=io.BytesIO(zip_bytes), \n",
    "    length=len(zip_bytes)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd61089",
   "metadata": {},
   "source": [
    "The model parameters are now in place to be used for making predictions. The zip file shows up in the Minio UI:\n",
    "\n",
    "![Minio UI](minio_ui_sdfmlm.png)\n",
    "![Minio UI]({attach}minio_ui_sdfmlm.png){ width=100% }\n",
    "\n",
    "The reason that we went through the process of uploading the model parameters in an external storage service is to show how they can be hosted in an external location. By signing the model parameters before we store them in the minio service, we can be sure that the parameters are not tampered with even if the minio service is compromised. Because we signed the model parameters, the attacker would also need to figure out the secret key to be able to modify the model parameters that the deployed model is using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3746650",
   "metadata": {},
   "source": [
    "## Making Predictions with the Model\n",
    "\n",
    "We now have a working model that accepts Pandas dataframes as input and also returns predictions in dataframes. This is useful in the context of model training, but makes integrating the model with other software components a lot more complicated. To make the model easier to use, we'll need to create input and output schemas for the model and also create a wrapper class that provides a consistent interface for the model.\n",
    "\n",
    "We'll create the model's input and output schemas with the [pydantic package](https://docs.pydantic.dev/), which is used for data validation. By creating the schemas using this package we're able to fully document the inputs that the model accepts and the expected outputs of the model we're going to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d111b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e41921",
   "metadata": {},
   "source": [
    "To begin, we'll define the allowed values for the categorical variables. The model uses three categorical variables, so we'll define three Enum classes that contain the values accepted for these variables. By using enumerated values, we can ensure that the model can only receive values in these inputs that it has previously seen in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0994eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class GeneralHealth(str, Enum):\n",
    "    \"\"\"How would you say that in general your health is?\"\"\"\n",
    "    EXCELLENT = \"EXCELLENT\"\n",
    "    VERY_GOOD = \"VERY_GOOD\"\n",
    "    GOOD = \"GOOD\"\n",
    "    FAIR = \"FAIR\"\n",
    "    POOR = \"POOR\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def map(value) -> float:\n",
    "        mapping = {\n",
    "            \"EXCELLENT\": 1.0,\n",
    "            \"VERY_GOOD\": 2.0,\n",
    "            \"GOOD\": 3.0,\n",
    "            \"FAIR\": 4.0,\n",
    "            \"POOR\": 5.0\n",
    "        }\n",
    "        return mapping[value]\n",
    "\n",
    "    \n",
    "class Age(str, Enum):\n",
    "    \"\"\"How old are you?\"\"\"\n",
    "    EIGHTEEN_TO_TWENTY_FOUR = \"EIGHTEEN_TO_TWENTY_FOUR\"\n",
    "    TWENTY_FIVE_TO_TWENTY_NINE = \"TWENTY_FIVE_TO_TWENTY_NINE\"\n",
    "    THIRTY_TO_THIRTY_FOUR = \"THIRTY_TO_THIRTY_FOUR\"\n",
    "    THIRTY_FIVE_TO_THIRTY_NINE = \"THIRTY_FIVE_TO_THIRTY_NINE\"\n",
    "    FORTY_TO_FORTY_FOUR = \"FORTY_TO_FORTY_FOUR\"\n",
    "    FORTY_FIVE_TO_FORTY_NINE = \"FORTY_FIVE_TO_FORTY_NINE\"\n",
    "    FIFTY_TO_FIFTY_FOUR = \"FIFTY_TO_FIFTY_FOUR\"\n",
    "    FIFTY_FIVE_TO_FIFTY_NINE = \"FIFTY_FIVE_TO_FIFTY_NINE\"\n",
    "    SIXTY_TO_SIXTY_FOUR = \"SIXTY_TO_SIXTY_FOUR\"\n",
    "    SIXTY_FIVE_TO_SIXTY_NINE = \"SIXTY_FIVE_TO_SIXTY_NINE\"\n",
    "    SEVENTY_TO_SEVENTY_FOUR = \"SEVENTY_TO_SEVENTY_FOUR\"\n",
    "    SEVENTY_FIVE_TO_SEVENTY_NINE = \"SEVENTY_FIVE_TO_SEVENTY_NINE\"\n",
    "    EIGHTY_OR_OLDER = \"EIGHTY_OR_OLDER\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def map(value) -> float:\n",
    "        mapping = {\n",
    "            \"EIGHTEEN_TO_TWENTY_FOUR\": 1.0,\n",
    "            \"TWENTY_FIVE_TO_TWENTY_NINE\": 2.0,\n",
    "            \"THIRTY_TO_THIRTY_FOUR\": 3.0,\n",
    "            \"THIRTY_FIVE_TO_THIRTY_NINE\": 4.0,\n",
    "            \"FORTY_TO_FORTY_FOUR\": 5.0,\n",
    "            \"FORTY_FIVE_TO_FORTY_NINE\": 6.0,\n",
    "            \"FIFTY_TO_FIFTY_FOUR\": 7.0,\n",
    "            \"FIFTY_FIVE_TO_FIFTY_NINE\": 8.0,\n",
    "            \"SIXTY_TO_SIXTY_FOUR\": 9.0,\n",
    "            \"SIXTY_FIVE_TO_SIXTY_NINE\": 10.0,\n",
    "            \"SEVENTY_TO_SEVENTY_FOUR\": 11.0,\n",
    "            \"SEVENTY_FIVE_TO_SEVENTY_NINE\": 12.0,\n",
    "            \"EIGHTY_OR_OLDER\": 13.0\n",
    "        }\n",
    "        return mapping[value]\n",
    "    \n",
    "\n",
    "class Income(str, Enum):\n",
    "    \"\"\"What is your income?\"\"\"\n",
    "    LESS_THAN_10K = \"LESS_THAN_10K\"\n",
    "    BETWEEN_10K_AND_15K = \"BETWEEN_10K_AND_15K\"\n",
    "    BETWEEN_15K_AND_20K = \"BETWEEN_15K_AND_20K\"\n",
    "    BETWEEN_20K_AND_25K = \"BETWEEN_20K_AND_25K\"\n",
    "    BETWEEN_25K_AND_35K = \"BETWEEN_25K_AND_35K\"\n",
    "    BETWEEN_35K_AND_50K = \"BETWEEN_35K_AND_50K\"\n",
    "    BETWEEN_50K_AND_75K = \"BETWEEN_50K_AND_75K\"\n",
    "    SEVENTY_FIVE_THOUSAND_OR_MORE = \"SEVENTY_FIVE_THOUSAND_OR_MORE\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def map(value) -> float:\n",
    "        mapping = {\n",
    "            \"LESS_THAN_10K\": 1.0,\n",
    "            \"BETWEEN_10K_AND_15K\": 2.0,\n",
    "            \"BETWEEN_15K_AND_20K\": 3.0,\n",
    "            \"BETWEEN_20K_AND_25K\": 4.0,\n",
    "            \"BETWEEN_25K_AND_35K\": 5.0,\n",
    "            \"BETWEEN_35K_AND_50K\": 6.0,\n",
    "            \"BETWEEN_50K_AND_75K\": 7.0,\n",
    "            \"SEVENTY_FIVE_THOUSAND_OR_MORE\": 8.0\n",
    "        }\n",
    "        return mapping[value]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c127e",
   "metadata": {},
   "source": [
    "The enum classes contain the values that were originally found in the training dataset. These variables were actually encoded as numbers in the dataset, so we also added a map() method to each Enum class that returns the corresponding number for the enumerated value passed into it. We'll be using the map() method of each Enum class later. \n",
    "\n",
    "If we didn't provide these enumerated values and the mapping, we'd be asking the user of the model to encode the values before sending them to the model. They would have to read and understand the dataset documentation to create their prediction request. By creating enumerations for the categorical values, we make it much easier to use the model. \n",
    "\n",
    "Now that we have the categorical variables defined, we can define the input schema for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b5c5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class DiabetesRiskModelInput(BaseModel):\n",
    "    body_mass_index: Optional[int] = Field(ge=15, le=60, description=\"Body Mass Index.\")\n",
    "    general_health: Optional[GeneralHealth] = Field(description=\"How would you say that in general your health is?\")\n",
    "    age: Optional[Age] = Field(description=\"How old are you?\")\n",
    "    income: Optional[Income] = Field(description=\"What is your income?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31338da9",
   "metadata": {},
   "source": [
    "The schema is called \"DiabetesRiskModelInput\" and contains fields for each variable found in the dataset. We're using the Enum classes we defined above for the categorical fields, and we defined a field for the numerical variable. Each numerical field has a range of allowed values that matches the range of the numerical variable found in the dataset. Each field also has a description of the variable that helps the user of the model to correctly feed data to the model. We only have 4 input variables because the feature selection process removed 17 features from the training set of the model.\n",
    "\n",
    "The process of creating an input data schema exposes information found in the dataset that the model was originally trained on to the user of the model. For example, the body_mass_index variable only allows values between 15 and 60, which is the range of the variable in the training set.\n",
    "\n",
    "To show how the schema classes work, let's try to instantiate the DiabetesRiskModelInput class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5134262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiabetesRiskModelInput(body_mass_index=20, general_health=<GeneralHealth.VERY_GOOD: 'VERY_GOOD'>, age=<Age.THIRTY_TO_THIRTY_FOUR: 'THIRTY_TO_THIRTY_FOUR'>, income=<Income.BETWEEN_20K_AND_25K: 'BETWEEN_20K_AND_25K'>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_instance = DiabetesRiskModelInput(\n",
    "    body_mass_index=20,\n",
    "    general_health=GeneralHealth.VERY_GOOD,\n",
    "    age=Age.THIRTY_TO_THIRTY_FOUR,\n",
    "    income=Income.BETWEEN_20K_AND_25K\n",
    ")\n",
    "\n",
    "input_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4622c0fb",
   "metadata": {},
   "source": [
    "The instance of the schema class contains all of the information needed to make a a prediction.\n",
    "\n",
    "Now let's try to instantiate it with values that are not allowed by the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "145c94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for DiabetesRiskModelInput\n",
      "body_mass_index\n",
      "  ensure this value is greater than or equal to 15 (type=value_error.number.not_ge; limit_value=15)\n",
      "ValidationError exception raised!\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "\n",
    "try:\n",
    "    input_instance = DiabetesRiskModelInput(\n",
    "        body_mass_index=10,\n",
    "        general_health=GeneralHealth.VERY_GOOD,\n",
    "        age=Age.THIRTY_TO_THIRTY_FOUR,\n",
    "        income=Income.BETWEEN_20K_AND_25K)\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "    print(\"ValidationError exception raised!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d8f84",
   "metadata": {},
   "source": [
    "The class was not instantiated succesfully because the value for body_mass_index is too low and the model cannot accept it. By using the pydantic package, we're able to describe what values the model is able to accept.\n",
    "\n",
    "We can also ommit values because they are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "105383b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiabetesRiskModelInput(body_mass_index=20, general_health=None, age=<Age.THIRTY_TO_THIRTY_FOUR: 'THIRTY_TO_THIRTY_FOUR'>, income=<Income.BETWEEN_20K_AND_25K: 'BETWEEN_20K_AND_25K'>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_instance = DiabetesRiskModelInput(\n",
    "    body_mass_index=20,\n",
    "    age=Age.THIRTY_TO_THIRTY_FOUR,\n",
    "    income=Income.BETWEEN_20K_AND_25K)\n",
    "\n",
    "input_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e34c69",
   "metadata": {},
   "source": [
    "In this case, we did not provide a value for general_health, which is filled in with a value of \"None\". We can do this because the model has built-in imputers that can provide a default value when it is not provided by the user of the model. \n",
    "\n",
    "Now that we have the model's input schema defined, we'll define the output schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43cabc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesRisk(str, Enum):\n",
    "    \"\"\"Risk of diabetes.\"\"\"\n",
    "    NO_DIABETES = \"NO_DIABETES\"\n",
    "    DIABETES = \"DIABETES\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def map(value: float) -> str:\n",
    "        mapping = {\n",
    "            0.0: DiabetesRisk.NO_DIABETES,\n",
    "            1.0: DiabetesRisk.DIABETES\n",
    "        }\n",
    "        return mapping[value]\n",
    "\n",
    "    \n",
    "class DiabetesRiskModelOutput(BaseModel):\n",
    "    \"\"\"Diabetes risk model output.\"\"\"\n",
    "    diabetes_risk: DiabetesRisk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e1f11",
   "metadata": {},
   "source": [
    "The model is a classification model and the output schema simply enumerates the classes that the model can predict. We also added a map() method to the DiabetesRisk class in order to map the number that is output by the model to a value that can be returned to the user.\n",
    "\n",
    "One of the benefits of using the pydantic package is that each schema class can create a JSON Schema description for itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca08e547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'DiabetesRiskModelOutput',\n",
       " 'description': 'Diabetes risk model output.',\n",
       " 'type': 'object',\n",
       " 'properties': {'diabetes_risk': {'$ref': '#/definitions/DiabetesRisk'}},\n",
       " 'required': ['diabetes_risk'],\n",
       " 'definitions': {'DiabetesRisk': {'title': 'DiabetesRisk',\n",
       "   'description': 'Risk of diabetes.',\n",
       "   'enum': ['NO_DIABETES', 'DIABETES'],\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_schema = DiabetesRiskModelOutput.schema()\n",
    "\n",
    "json_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b87743",
   "metadata": {},
   "source": [
    "JSON schemas are useful for documenting data structures. We'll use this JSON schema later in order to automatically build documentation for the deployed model.\n",
    "\n",
    "Now that we have the input and output schemas defined, now we can tie it all together by creating a wrapper class for the model. To do this we'll use the [ml_base package](https://pypi.org/project/ml-base/). \n",
    "\n",
    "To install the ml_base package, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50987d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ml_base\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aeb7d8",
   "metadata": {},
   "source": [
    "The ml_base package defines a simple base class for model prediction code that allows us to \"wrap\" the prediction code for a model in a class that follows the MLModel interface. This interface publishes this information about the model:\n",
    "\n",
    "- Qualified Name, a unique identifier for the model.\n",
    "- Display Name, a friendly name for the model used in user interfaces.\n",
    "- Description, a description for the model.\n",
    "- Version, semantic version of the model codebase.\n",
    "- Input Schema, an object that describes the model's input data.\n",
    "- Output Schema, an object that describes the model's output schema.\n",
    "\n",
    "The MLModel interface dictates that the model class implements two methods:\n",
    "\n",
    "- \\_\\_init\\_\\_(), the initialization method which loads any model parameters needed to make predictions\n",
    "- predict(), prediction method that receives model inputs makes a prediction and returns model outputs\n",
    "\n",
    "By using the MLModel base class we'll be able to do more interesting things later with the model. If you'd like to learn more about the ml_base package, [here](https://schmidtbri.github.io/ml-base/basic/) is some documentation about it.\n",
    "\n",
    "We'll define the wrapper class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "349a0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "from itsdangerous import Signer\n",
    "from minio import Minio\n",
    "from ml_base import MLModel\n",
    "\n",
    "\n",
    "class DiabetesRiskModel(MLModel):\n",
    "    \"\"\"Prediction logic for the Diabetes Risk Model.\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def display_name(self) -> str:\n",
    "        return \"Diabetes Risk Model\"\n",
    "\n",
    "    @property\n",
    "    def qualified_name(self) -> str:\n",
    "        return \"diabetes_risk_model\"\n",
    "\n",
    "    @property\n",
    "    def description(self) -> str:\n",
    "        return \"Model to predict the diabetes risk of a patient.\"\n",
    "\n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return \"0.1.0\"\n",
    "\n",
    "    @property\n",
    "    def input_schema(self):\n",
    "        return DiabetesRiskModelInput\n",
    "\n",
    "    @property\n",
    "    def output_schema(self):\n",
    "        return DiabetesRiskModelOutput\n",
    "\n",
    "    def __init__(self, model_parameters_version: str, \n",
    "                 model_files_bucket: str, \n",
    "                 minio_url: str, \n",
    "                 minio_access_key: str, \n",
    "                 minio_secret_key: str,\n",
    "                 parameters_signing_key: str):\n",
    "        # retrieving values from environment variables if the values provided have ${} around them\n",
    "        if minio_access_key[0:2] == \"${\" and minio_access_key[-1] == \"}\":\n",
    "            minio_access_key = os.environ[minio_access_key[2:-1]]\n",
    "        \n",
    "        if minio_secret_key[0:2] == \"${\" and minio_secret_key[-1] == \"}\":\n",
    "            minio_secret_key = os.environ[minio_secret_key[2:-1]]\n",
    "            \n",
    "        if parameters_signing_key[0:2] == \"${\" and parameters_signing_key[-1] == \"}\":\n",
    "            parameters_signing_key = os.environ[parameters_signing_key[2:-1]]\n",
    "        \n",
    "        minio_client = Minio(minio_url,\n",
    "                             access_key=minio_access_key,\n",
    "                             secret_key=minio_secret_key,\n",
    "                             secure=False)\n",
    "        try:\n",
    "            # accessing the model file stored in minio\n",
    "            response = minio_client.get_object(model_files_bucket, \n",
    "                                               f\"{self.qualified_name}-{self.version}-{model_parameters_version}.zip\")\n",
    "            zip_bytes = BytesIO(response.data)\n",
    "            \n",
    "            response.close()\n",
    "            response.release_conn()\n",
    "            \n",
    "            # unzipping the parameters\n",
    "            with zipfile.ZipFile(zip_bytes) as zf:\n",
    "                if \"signed_model.pkl\" not in zf.namelist():\n",
    "                    raise ValueError(\"Could not find signed model file in zip file.\")\n",
    "                signed_model_bytes = zf.read(\"signed_model.pkl\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Could not access model file.\") from e\n",
    "        \n",
    "        # checking the signed parameters\n",
    "        signer = Signer(parameters_signing_key)\n",
    "        unsigned_model_bytes = signer.unsign(signed_model_bytes)\n",
    "        \n",
    "        # unpickling the model object\n",
    "        self._model = pickle.loads(unsigned_model_bytes)\n",
    "    \n",
    "    def predict(self, data: DiabetesRiskModelInput) -> DiabetesRiskModelOutput:\n",
    "        if type(data) is not DiabetesRiskModelInput:\n",
    "            raise ValueError(\"Input must be of type 'DiabetesRiskModelInput'\")\n",
    "            \n",
    "        X = pd.DataFrame([[\n",
    "            None, None, None,\n",
    "            data.body_mass_index,\n",
    "            None, None, None, None, None, None, None, None, None,\n",
    "            GeneralHealth.map(data.general_health),\n",
    "            None, None, None, None,\n",
    "            Age.map(data.age),\n",
    "            None,\n",
    "            Income.map(data.income),\n",
    "        ]], columns=['HighBloodPressure', 'HighCholesterol', 'CholesterolChecked', 'BMI', 'Smoker', 'Stroke',\n",
    "                     'HeartDiseaseOrHeartAttack', 'PhysicalActivity', 'Fruits', 'Veggies',\n",
    "                     'HeavyAlchoholConsumption', 'AnyHealthcare', 'NoDoctorsVisitBecauseOfCost', \n",
    "                     'GeneralHealth', 'MentalHealth', 'PhysicalHealth', 'DifficultyWalking', 'Sex', \n",
    "                     'Age', 'Education', 'Income'])\n",
    "\n",
    "        y_hat = float(self._model.predict(X)[0])\n",
    "        \n",
    "        return DiabetesRiskModelOutput(diabetes_risk=DiabetesRisk.map(y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b004cc",
   "metadata": {},
   "source": [
    "The model class \\_\\_init\\_\\_() method loads the model parameters from the minio service, verifies the signature, and deserializes the pickle into a model object that we can use to make predictions. The predict() method uses the model object to make predictions. Notice that we mapped the enumerated values into the numbers that the model expects to see before making a prediction with the model, and also mapped the model's prediction back into an enumerated value that can be returned to the user.\n",
    "\n",
    "Let's instantiate the model class we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85a72d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiabetesRiskModel(\n",
    "    model_parameters_version=\"2023_03_17\", \n",
    "    model_files_bucket=\"model-files\", \n",
    "    minio_url=\"127.0.0.1:9000\", \n",
    "    minio_access_key=\"TEST\", \n",
    "    minio_secret_key=\"ASDFGHJKL\",\n",
    "    parameters_signing_key=\"wjtRFppXQpxTChQnNcQJKGlLHKJBmAHMepfFbqvOoUrnuxIsKdiLCrrypYFQsqcw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa721da8",
   "metadata": {},
   "source": [
    "When the model object is instantiated, the init method loaded the zip file that contains the model pickle file from the minio service, verified that the bytes have not been changed using the secret key, and deserialized the model. The model object is ready to use to make predictions.\n",
    "\n",
    "We can make a prediction with the model by first building a DiabetesRiskModelInput object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da0e0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_instance = DiabetesRiskModelInput(\n",
    "    body_mass_index=20,\n",
    "    general_health=GeneralHealth.VERY_GOOD,\n",
    "    age=Age.THIRTY_TO_THIRTY_FOUR,\n",
    "    income=Income.BETWEEN_20K_AND_25K\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d52ba1",
   "metadata": {},
   "source": [
    "Then use the input object with the model's predict() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9913427f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiabetesRiskModelOutput(diabetes_risk=<DiabetesRisk.NO_DIABETES: 'NO_DIABETES'>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(input_instance)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2346e9",
   "metadata": {},
   "source": [
    "The model predicted that the patient does not have diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ea6ee",
   "metadata": {},
   "source": [
    "## Creating a RESTful Service\n",
    "\n",
    "Now that we have a working model that loads and verifies parameters from minio, we can deploy the model into a service. To do this, we won't need to write any extra code, we can leverage the [rest_model_service package](https://pypi.org/project/rest-model-service/) to provide the RESTful API for the service. You can learn more about the package in [this blog post](https://www.tekhnoal.com/rest-model-service.html).\n",
    "\n",
    "To install the package, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5058183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rest_model_service\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3c7a3",
   "metadata": {},
   "source": [
    "To create a service for our model, all that is needed is that we add a YAML configuration file to the project. The configuration file looks like this:\n",
    "\n",
    "```yaml\n",
    "service_title: Diabetes Risk Model Service\n",
    "models:\n",
    "  - class_path: diabetes_risk_model.prediction.model.DiabetesRiskModel\n",
    "    create_endpoint: true\n",
    "    configuration:\n",
    "      model_parameters_version: \"2023_03_17\"\n",
    "      model_files_bucket: model-files\n",
    "      minio_url: 127.0.0.1:9000\n",
    "      minio_access_key: TEST\n",
    "      minio_secret_key: ASDFGHJKL\n",
    "      parameters_signing_key: wjtRFppXQpxTChQnNcQJKGlLHKJBmAHMepfFbqvOoUrnuxIsKdiLCrrypYFQsqcw\n",
    "```\n",
    "\n",
    "The \"service_title\" field is the name of the service as it will appear in the documentation. The \"models\" field is an array that contains the details of the models we would like to deploy in the service. The \"class_path\" points at the MLModel class that implements the model's prediction logic. \n",
    "\n",
    "Using the configuration file, we're able to create an OpenAPI specification file for the model service by executing these commands:\n",
    "\n",
    "```bash\n",
    "export PYTHONPATH=./\n",
    "generate_openapi --configuration_file=configuration/rest_config.yaml --output_file=service_contract.yaml\n",
    "```\n",
    "\n",
    "The generate_openapi command generated the service_contract.yaml file which contains the [OpenAPI specification](https://en.wikipedia.org/wiki/OpenAPI_Specification) for the model service. The \"/api/models/diabetes_risk_model/prediction\" endpoint is the one we'll call to make predictions with the model. The model's input and output schemas were automatically extracted and added to the specification. The service_contract.yaml is available in the root of the Github repository.\n",
    "\n",
    "To run the model service locally, execute these commands:\n",
    "\n",
    "```bash\n",
    "export REST_CONFIG=./configuration/rest_config.yaml\n",
    "uvicorn rest_model_service.main:app --reload\n",
    "```\n",
    "\n",
    "The service comes up and can be accessed in a web browser at http://127.0.0.1:8000. When you access that URL you will be redirected to the documentation page that is generated by the FastAPI package:\n",
    "\n",
    "![FastAPI Documentation](fastapi_documentation_sdfmlm.png)\n",
    "![FastAPI Documentation]({attach}fastapi_documentation_sdfmlm.png){ width=100% }\n",
    "\n",
    "\n",
    "The documentation allows you to make requests against the API in order to try it out. Here's a prediction request against the diabetes risk model:\n",
    "\n",
    "![Prediction Request](prediction_request_sdfmlm.png)\n",
    "![Prediction Request]({attach}prediction_request_sdfmlm.png){ width=100% }\n",
    "\n",
    "And the prediction result:\n",
    "\n",
    "![Prediction Result](prediction_result_sdfmlm.png)\n",
    "![Prediction Result]({attach}prediction_result_sdfmlm.png){ width=100% }\n",
    "\n",
    "By using the MLModel base class provided by the ml_base package and the REST service framework provided by the rest_model_service package we're able to quickly stand up a service to host the model. We're done with the model service, so we'll stop it with CTL+C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866953c",
   "metadata": {},
   "source": [
    "## Creating a Docker Image\n",
    "\n",
    "Now that we have a working model and model service, we'll need to deploy it somewhere. We'll start by deploying the service locally using Docker.\n",
    "\n",
    "Let's create a docker image and run it locally. The docker image is generated using instructions in the Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "# syntax=docker/dockerfile:1\n",
    "FROM python:3.9-slim\n",
    "\n",
    "ARG BUILD_DATE\n",
    "\n",
    "LABEL org.opencontainers.image.title=\"Diabetes Risk Model Service\"\n",
    "LABEL org.opencontainers.image.description=\"Diabetes Risk Model Service.\"\n",
    "LABEL org.opencontainers.image.created=$BUILD_DATE\n",
    "LABEL org.opencontainers.image.authors=\"6666331+schmidtbri@users.noreply.github.com\"\n",
    "LABEL org.opencontainers.image.source=\"https://github.com/schmidtbri/securing-parameters-for-ml-models\"\n",
    "LABEL org.opencontainers.image.version=\"0.1.0\"\n",
    "LABEL org.opencontainers.image.licenses=\"MIT License\"\n",
    "LABEL org.opencontainers.image.base.name=\"python:3.9-slim\"\n",
    "\n",
    "WORKDIR /service\n",
    "\n",
    "ARG USERNAME=service-user\n",
    "ARG USER_UID=10000\n",
    "ARG USER_GID=10000\n",
    "\n",
    "# install packages\n",
    "RUN apt-get update -y && \\\n",
    "    apt-get install -y --no-install-recommends sudo && \\\n",
    "    apt-get install -y --no-install-recommends libgomp1 && \\\n",
    "    apt-get clean && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# create a user\n",
    "RUN groupadd --gid $USER_GID $USERNAME && \\\n",
    "    useradd --uid $USER_UID --gid $USER_GID -m $USERNAME && \\\n",
    "    echo $USERNAME ALL=\\(root\\) NOPASSWD:ALL > /etc/sudoers.d/$USERNAME && \\\n",
    "    chmod 0440 /etc/sudoers.d/$USERNAME\n",
    "\n",
    "# installing dependencies\n",
    "COPY ./service_requirements.txt ./service_requirements.txt\n",
    "RUN pip install --no-cache -r service_requirements.txt\n",
    "\n",
    "# copying model code and license\n",
    "COPY ./diabetes_risk_model ./diabetes_risk_model\n",
    "COPY ./LICENSE ./LICENSE\n",
    "\n",
    "USER $USERNAME\n",
    "\n",
    "RUN sudo chown $USERNAME:$USERNAME -R /service && \\\n",
    "    sudo chmod -R +rw /service  && \\\n",
    "    sudo mkdir -p  /var/folders/vb && \\\n",
    "    sudo chown $USERNAME:$USERNAME -R /var/folders/vb && \\\n",
    "    sudo chmod -R +rw /var/folders/vb\n",
    "\n",
    "CMD [\"uvicorn\", \"rest_model_service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "This Dockerfile is used by this docker command to create a docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09c74c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t diabetes_risk_model_service:0.1.0 ../\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b2c46a",
   "metadata": {},
   "source": [
    "To make sure everything worked as expected, we'll look through the docker images in our system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6de9572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_risk_model_service       0.1.0     92d771f815ee   48 seconds ago   1.2GB\r\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep diabetes_risk_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2cb9e",
   "metadata": {},
   "source": [
    "The diabetes_risk_model_service image is listed. To test the model service docker image with the minio docker container that is already running, we'll need to create a network for them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "580f74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7e66d4b4dd92e454d4a662c51678a3e05d61ca1389b566ec07afef7630cb1b93\r\n"
     ]
    }
   ],
   "source": [
    "!docker network create local-test-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd46c9",
   "metadata": {},
   "source": [
    "Next, we'll connect the running minio container to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71f56db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker network connect local-test-network minio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f46e2",
   "metadata": {},
   "source": [
    "Now we can start the model service docker image connected to the same network as the minio container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28dad148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a9b9f3b22af0c2b2e74f1c01e062c56c921b9f689c0284b308a3e93ed6990eba\r\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    --name diabetes_risk_model_service \\\n",
    "    -p 8000:8000 \\\n",
    "    --net local-test-network \\\n",
    "    -v $(pwd)/../configuration:/service/configuration \\\n",
    "    -e REST_CONFIG=./configuration/docker_rest_config.yaml \\\n",
    "    diabetes_risk_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec699b",
   "metadata": {},
   "source": [
    "Notice that we provided the configuration YAML file to the service running in the docker image by mounting the local configuration folder.\n",
    "\n",
    "To make sure the server process started up correctly, we'll look at the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27a014c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\r\n",
      "INFO:     Waiting for application startup.\r\n",
      "INFO:     Application startup complete.\r\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\r\n"
     ]
    }
   ],
   "source": [
    "!docker logs diabetes_risk_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b9d52",
   "metadata": {},
   "source": [
    "The logs don't show any errors, looks like the model parameters were loaded and verified correctly from the minio service when the service started up.\n",
    "\n",
    "The service should be accessible on port 8000 of localhost, so we'll try to make a prediction using the curl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d377521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"diabetes_risk\":\"NO_DIABETES\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://0.0.0.0:8000/api/models/diabetes_risk_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \\\n",
    "    \"body_mass_index\": 20, \\\n",
    "    \"general_health\": \"EXCELLENT\", \\\n",
    "    \"age\": \"EIGHTEEN_TO_TWENTY_FOUR\", \\\n",
    "    \"income\": \"LESS_THAN_10K\" \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fa34a",
   "metadata": {},
   "source": [
    "The model predicted that the patient does not have diabetes.\n",
    "\n",
    "We're done with the docker containers, so we'll shut them down along with the docker network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "faeec95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_risk_model_service\n",
      "diabetes_risk_model_service\n",
      "minio\n",
      "minio\n",
      "local-test-network\n"
     ]
    }
   ],
   "source": [
    "!docker kill diabetes_risk_model_service\n",
    "!docker rm diabetes_risk_model_service\n",
    "\n",
    "!docker kill minio\n",
    "!docker rm minio\n",
    "\n",
    "!docker network rm local-test-network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f58c42",
   "metadata": {},
   "source": [
    "## Creating a Kubernetes Cluster\n",
    "\n",
    "To show the system in action, well deploy the model service and the minio service to a Kubernetes cluster. A local cluster can be easily started by using [minikube](https://minikube.sigs.k8s.io/docs/). Installation instructions can be found [here](https://minikube.sigs.k8s.io/docs/start/).\n",
    "\n",
    "To start the minikube cluster execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "894185ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  minikube v1.28.0 on Darwin 13.2.1\n",
      "  minikube 1.29.0 is available! Download it: https://github.com/kubernetes/minikube/releases/tag/v1.29.0\n",
      "  To disable this notice, run: 'minikube config set WantUpdateNotification false'\n",
      "\n",
      "  Using the docker driver based on existing profile\n",
      "  Starting control plane node minikube in cluster minikube\n",
      "  Pulling base image ...\n",
      "  Restarting existing docker container for \"minikube\" ...\n",
      "  Preparing Kubernetes v1.25.3 on Docker 20.10.20 ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "  Verifying Kubernetes components...\n",
      "     Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "     Using image docker.io/kubernetesui/metrics-scraper:v1.0.8\n",
      "     Using image docker.io/kubernetesui/dashboard:v2.7.0\n",
      "  Some dashboard features require the metrics-server addon. To enable all features please run:\n",
      "\n",
      "\tminikube addons enable metrics-server\t\n",
      "\n",
      "\n",
      "  Enabled addons: storage-provisioner, default-storageclass, dashboard\n",
      "  Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\n"
     ]
    }
   ],
   "source": [
    "!minikube start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf655fa",
   "metadata": {},
   "source": [
    "Let's view all of the pods running in the minikube cluster to make sure we can connect to it using the kubectl command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22f6b648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE              NAME                                        READY   STATUS    RESTARTS       AGE\r\n",
      "kube-system            coredns-565d847f94-2v6l9                    1/1     Running   15 (82s ago)   72d\r\n",
      "kube-system            etcd-minikube                               1/1     Running   15 (2d ago)    72d\r\n",
      "kube-system            kube-apiserver-minikube                     1/1     Running   14 (2d ago)    72d\r\n",
      "kube-system            kube-controller-manager-minikube            1/1     Running   15 (82s ago)   72d\r\n",
      "kube-system            kube-proxy-ztbgd                            1/1     Running   14 (2d ago)    72d\r\n",
      "kube-system            kube-scheduler-minikube                     1/1     Running   14 (2d ago)    72d\r\n",
      "kube-system            storage-provisioner                         1/1     Running   26 (2d ago)    72d\r\n",
      "kubernetes-dashboard   dashboard-metrics-scraper-b74747df5-x559p   1/1     Running   14 (2d ago)    72d\r\n",
      "kubernetes-dashboard   kubernetes-dashboard-57bbdc5f89-9jvln       1/1     Running   18 (82s ago)   72d\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods -A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db1446",
   "metadata": {},
   "source": [
    "Looks like we can connect, we're ready to start deploying the model service to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a81b1b",
   "metadata": {},
   "source": [
    "## Creating a Namespace\n",
    "\n",
    "We'll first create a namespace to hold the resources for our model service. The resource definition is in the kubernetes/namespace.yaml file. To apply the manifest to the cluster, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32178ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/model-services created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f ../kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d80cfe",
   "metadata": {},
   "source": [
    "The namespace was created. To take a look at the namespaces, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a29a1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   STATUS   AGE\r\n",
      "default                Active   72d\r\n",
      "kube-node-lease        Active   72d\r\n",
      "kube-public            Active   72d\r\n",
      "kube-system            Active   72d\r\n",
      "kubernetes-dashboard   Active   72d\r\n",
      "model-services         Active   3s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a6d77",
   "metadata": {},
   "source": [
    "The new namespace appears in the listing along with other namespaces created by default by the system. To use the new namespace for the rest of the operations, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73de217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"minikube\" modified.\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl config set-context --current --namespace=model-services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98fe3a",
   "metadata": {},
   "source": [
    "Now the rest of the kubectl commands that we execute will automatically be applied in the \"model-services\" namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a81068",
   "metadata": {},
   "source": [
    "## Creating the Storage Service\n",
    "\n",
    "To store the model parameters, we'll need to deploy minio to the cluster as a service. We can do this by using the helm tool and a helm chart provided by minio. \n",
    "\n",
    "First let's add the minio helm repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54e0cebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"minio\" has been added to your repositories\r\n"
     ]
    }
   ],
   "source": [
    "!helm repo add minio https://charts.min.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35544a8a",
   "metadata": {},
   "source": [
    "The minion helm repository is now available to be used.\n",
    "\n",
    "Let's apply the minio helm chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c726d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: minio\r\n",
      "LAST DEPLOYED: Sat Mar 18 00:15:07 2023\r\n",
      "NAMESPACE: model-services\r\n",
      "STATUS: deployed\r\n",
      "REVISION: 1\r\n",
      "TEST SUITE: None\r\n",
      "NOTES:\r\n",
      "MinIO can be accessed via port 9000 on the following DNS name from within your cluster:\r\n",
      "minio.model-services.svc.cluster.local\r\n",
      "\r\n",
      "To access MinIO from localhost, run the below commands:\r\n",
      "\r\n",
      "  1. export POD_NAME=$(kubectl get pods --namespace model-services -l \"release=minio\" -o jsonpath=\"{.items[0].metadata.name}\")\r\n",
      "\r\n",
      "  2. kubectl port-forward $POD_NAME 9000 --namespace model-services\r\n",
      "\r\n",
      "Read more about port forwarding here: http://kubernetes.io/docs/user-guide/kubectl/kubectl_port-forward/\r\n",
      "\r\n",
      "You can now access MinIO server on http://localhost:9000. Follow the below steps to connect to MinIO server with mc client:\r\n",
      "\r\n",
      "  1. Download the MinIO mc client - https://min.io/docs/minio/linux/reference/minio-mc.html#quickstart\r\n",
      "\r\n",
      "  2. export MC_HOST_minio-local=http://$(kubectl get secret --namespace model-services minio -o jsonpath=\"{.data.rootUser}\" | base64 --decode):$(kubectl get secret --namespace model-services minio -o jsonpath=\"{.data.rootPassword}\" | base64 --decode)@localhost:9000\r\n",
      "\r\n",
      "  3. mc ls minio-local\r\n"
     ]
    }
   ],
   "source": [
    "!helm install minio --set rootUser=TEST,rootPassword=ASDFGHJKL \\\n",
    "  --set persistence.enabled=true \\\n",
    "  --set persistence.size=2Gi \\\n",
    "  --set resources.requests.cpu=1 \\\n",
    "  --set resources.limits.cpu=2 \\\n",
    "  --set resources.requests.memory=250Mi \\\n",
    "  --set resources.limits.memory=500Mi \\\n",
    "  --set mode=distributed,replicas=2 \\\n",
    "  minio/minio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0521288f",
   "metadata": {},
   "source": [
    "The minio service was installed. We can view the pods running to see if it's running correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91539df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      READY   STATUS    RESTARTS   AGE\r\n",
      "minio-0   1/1     Running   0          82s\r\n",
      "minio-1   1/1     Running   0          82s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4469fee",
   "metadata": {},
   "source": [
    "The minio service is running in two pods. The minio service is accessible through a set of Kubernetes Services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8598c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\r\n",
      "minio           ClusterIP   10.108.159.154   <none>        9000/TCP   2m4s\r\n",
      "minio-console   ClusterIP   10.110.151.171   <none>        9001/TCP   2m4s\r\n",
      "minio-svc       ClusterIP   None             <none>        9000/TCP   2m4s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93fd04",
   "metadata": {},
   "source": [
    "We'll upload the model parameters by accessing the minio-console service. To do that, we'll need to connect to the minio instance using using port forwarding. Port forwarding is a simple way to connect to a service running in the cluster from the local environment, it simply forwards all traffic from a local port to a remote port that is hosting the service.\n",
    "\n",
    "To start port forwarding the minio-console service, execute this command:\n",
    "\n",
    "```bash\n",
    "minikube service minio-console --url -n model-services\n",
    "```\n",
    "\n",
    "This command has to run continuously for the port forwarding to work. The UI of the minio instance that is running in the cluster is now available locally:\n",
    "\n",
    "![Minio UI](minio_kubernetes_ui_sdfmlm.png)\n",
    "![Minio UI]({attach}minio_kubernetes_ui_sdfmlm.png){ width=100% }\n",
    "\n",
    "In order to keep things short, I created the \"model-files\" bucket and uploaded model .zip file that were working with above.\n",
    "\n",
    "We now have model parameters for the model service to access. Now ready to deploy the model service to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fe396",
   "metadata": {},
   "source": [
    "## Creating a Deployment and Service\n",
    "\n",
    "The model service is deployed by using Kubernetes resources. These are:\n",
    "\n",
    "- Secret: a set of configuration string that are stored by Kubernetes that can be provided to Pods running within the cluster. The secrets will be the minio login details and the secret key used to verify the model parameters.\n",
    "- ConfigMap: a set of configuration options, in this case it is a simple YAML file that will be loaded into the running container as a volume mount. This resource allows us to change the configuration of the model service without having to modify the Docker image. \n",
    "- Deployment: a declarative way to manage a set of Pods, the model service pods are managed through the Deployment.\n",
    "- Service: a way to expose a set of Pods in a Deployment, the model service is made available to the outside world through the Service.\n",
    "\n",
    "We're almost ready to deploy the model service, but before starting it we'll need to send the docker image from the local docker daemon to the minikube image cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3d262664",
   "metadata": {},
   "outputs": [],
   "source": [
    "!minikube image load diabetes_risk_model_service:0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe5a1e",
   "metadata": {},
   "source": [
    "We can view the images in the minikube cache with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "895b2e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker.io/library/diabetes_risk_model_service:0.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!minikube image ls | grep diabetes_risk_model_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc72c6",
   "metadata": {},
   "source": [
    "The model service will need to access the YAML configuration file that we used for the local service above. This is file is in the /configuration folder and is called \"kubernetes_rest_config.yaml\", its customized for the kubernetes environment we're building.\n",
    "\n",
    "To create a [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) for the service, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a74a8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/model-service-configuration created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create configmap model-service-configuration \\\n",
    "    --from-file=../configuration/kubernetes_rest_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce3cfe",
   "metadata": {},
   "source": [
    "The model service also needs to access three secrets:\n",
    "\n",
    "- minio access key, used for accessing the minio service\n",
    "- minio secret key, used for accessing the minio service\n",
    "- parameters signing key used for verifying the model parameters\n",
    "\n",
    "These secrets can't be added to the ConfigMap because they need to be encrypted to be secure. We'll store these secrets as [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/) in kubernetes with these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c167cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/diabetes-risk-model-service-secrets created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create secret generic diabetes-risk-model-service-secrets \\\n",
    "    --from-literal=minio-access-key=TEST \\\n",
    "    --from-literal=minio-secret-key=ASDFGHJKL \\\n",
    "    --from-literal=parameters-signing-key=wjtRFppXQpxTChQnNcQJKGlLHKJBmAHMepfFbqvOoUrnuxIsKdiLCrrypYFQsqcw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349edeb2",
   "metadata": {},
   "source": [
    "The model service Deployment and Service are created within the Kubernetes cluster with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca350bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/diabetes-risk-model-deployment created\n",
      "service/diabetes-risk-model-service created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f ../kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4866c5",
   "metadata": {},
   "source": [
    "Lets view the Deployment to see if it is available yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dfc29f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                             READY   UP-TO-DATE   AVAILABLE   AGE\r\n",
      "diabetes-risk-model-deployment   1/1     1            1           65s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc21f2",
   "metadata": {},
   "source": [
    "To get an idea of how the service went through the startup process, let's look a the service logs. Let's get the names of the pods that are running the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32440004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-risk-model-deployment-ff7887475-5q2j5   1/1     Running   0          68s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods | grep diabetes-risk-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d342377",
   "metadata": {},
   "source": [
    "Using the pod name, we can get the logs from Kubernetes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d636c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [1]\r\n",
      "INFO:     Waiting for application startup.\r\n",
      "INFO:     Application startup complete.\r\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\r\n",
      "INFO:     172.17.0.1:35258 - \"GET /api/health/startup HTTP/1.1\" 503 Service Unavailable\r\n",
      "INFO:     172.17.0.1:35272 - \"GET /api/health/startup HTTP/1.1\" 503 Service Unavailable\r\n",
      "INFO:     172.17.0.1:55252 - \"GET /api/health/startup HTTP/1.1\" 503 Service Unavailable\r\n",
      "INFO:     172.17.0.1:55264 - \"GET /api/health/startup HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:55270 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49028 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49026 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49038 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49054 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:54738 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:54742 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:54758 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:54760 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:48658 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:48664 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:48674 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:48684 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49928 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49926 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49956 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49960 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:36756 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:36762 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:36772 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:36776 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:39302 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:39306 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:39310 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:39316 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:40184 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:40192 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:40214 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:40202 - \"GET /api/health HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49204 - \"GET /api/health/ready HTTP/1.1\" 200 OK\r\n",
      "INFO:     172.17.0.1:49202 - \"GET /api/health HTTP/1.1\" 200 OK\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl logs diabetes-risk-model-deployment-ff7887475-5q2j5 -c diabetes-risk-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f9f1d",
   "metadata": {},
   "source": [
    "Looks like the process started up correctly.\n",
    "\n",
    "The Kubernetes Service details look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab5084a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-risk-model-service   NodePort    10.99.180.41     <none>        80:31452/TCP   2m29s\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get services | grep diabetes-risk-model-service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a1887",
   "metadata": {},
   "source": [
    "We'll run another proxy process locally to be able to access the model service endpoint:\n",
    "\n",
    "```bash\n",
    "minikube service diabetes-risk-model-service --url -n model-services\n",
    "```\n",
    "\n",
    "The command outputs this URL:\n",
    "\n",
    "http://127.0.0.1:55659\n",
    "\n",
    "We can send a request to the model service through the local endpoint like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d326bd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"diabetes_risk\":\"NO_DIABETES\"}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "  'http://127.0.0.1:55659/api/models/diabetes_risk_model/prediction' \\\n",
    "  -H 'accept: application/json' \\\n",
    "  -H 'Content-Type: application/json' \\\n",
    "  -d '{ \\\n",
    "    \"body_mass_index\": 60, \\\n",
    "    \"general_health\": \"EXCELLENT\", \\\n",
    "    \"age\": \"EIGHTEEN_TO_TWENTY_FOUR\", \\\n",
    "    \"income\": \"LESS_THAN_10K\" \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1ce00",
   "metadata": {},
   "source": [
    "The model is deployed within Kubernetes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f7cb2",
   "metadata": {},
   "source": [
    "## Deleting the Resources\n",
    "\n",
    "We're done working with the Kubernetes resources, so we will delete them and shut down the cluster.\n",
    "\n",
    "To delete the model service Deployment and Service, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f519ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"diabetes-risk-model-deployment\" deleted\n",
      "service \"diabetes-risk-model-service\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f ../kubernetes/model_service.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dd01e",
   "metadata": {},
   "source": [
    "We'll also delete the ConfigMap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f26790fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap \"model-service-configuration\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete configmap model-service-configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67736f",
   "metadata": {},
   "source": [
    "Next, we'll delete the secrets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b81d38b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret \"diabetes-risk-model-service-secrets\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete secret diabetes-risk-model-service-secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da061aa5",
   "metadata": {},
   "source": [
    "To delete the minio deployment execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eebbc20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"minio\" uninstalled\r\n"
     ]
    }
   ],
   "source": [
    "!helm delete minio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf03f3",
   "metadata": {},
   "source": [
    "The minio service used [Persistent Volume Claims](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) to store data. Since these are not deleted with the minio  helm chart, we'll delete it with a kubectl command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56ceadd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim \"export-minio-0\" deleted\r\n",
      "persistentvolumeclaim \"export-minio-1\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete pvc -l app=minio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24653439",
   "metadata": {},
   "source": [
    "To delete the model-services namespace, execute this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3ccafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"model-services\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f ../kubernetes/namespace.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e785bc",
   "metadata": {},
   "source": [
    "To shut down the minikube cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "195232a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stopping node \"minikube\"  ...\n",
      "  Powering off \"minikube\" via SSH ...\n",
      "  1 node stopped.\n"
     ]
    }
   ],
   "source": [
    "!minikube stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdeb2d5",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "In this blog post we trained, validated, signed, and verified a set of model parameters to ensure that they remain secure. This process is needed because of the inherent security problems that Python pickles bring with them. The signing and verificationprocess added a little bit of complexity, but it's worth it to ensure the security of the model deployment. \n",
    "\n",
    "We also showed how to deploy the serialized model parameters to a storage service, and how to access them from the deployed model. We did this to show a common vulnerability of machine learning model deployments. Since a lot of model parameters are not deployed alongside the prediction code, they are deployed in a separate storage service from which they are loaded. This practice makes the deployment of model parameters faster, but adds another attack vector that needs to be secured. Since the model parameters are stored in a storage server, an attacker can access the storage service and modify the model parameters in order to do arbritrary code execution in the server where the model is deployed. By adding a signature verification process before the model parameters can be deserialized, we made the deployment of model parameters a little more secure.\n",
    "\n",
    "One way to improve this process is to make it into a plug-in that can be easily added to model training and prediction code, making it simpler to add to a training pipeline and model deployment. Another way to improve it is by adding a key cycling mechanism to ensure that secret keys do not remain in production for a long time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
